{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moduleName = [\n",
    "  'conv1', 'bn1', 'conv2', 'bn2', 'conv3', 'bn3',\n",
    "  'inception_3a_1x1_conv', 'inception_3a_1x1_bn',\n",
    "  'inception_3a_pool_conv', 'inception_3a_pool_bn',\n",
    "  'inception_3a_5x5_conv1', 'inception_3a_5x5_conv2', 'inception_3a_5x5_bn1', 'inception_3a_5x5_bn2',\n",
    "  'inception_3a_3x3_conv1', 'inception_3a_3x3_conv2', 'inception_3a_3x3_bn1', 'inception_3a_3x3_bn2',\n",
    "  'inception_3b_3x3_conv1', 'inception_3b_3x3_conv2', 'inception_3b_3x3_bn1', 'inception_3b_3x3_bn2',\n",
    "  'inception_3b_5x5_conv1', 'inception_3b_5x5_conv2', 'inception_3b_5x5_bn1', 'inception_3b_5x5_bn2',\n",
    "  'inception_3b_pool_conv', 'inception_3b_pool_bn',\n",
    "  'inception_3b_1x1_conv', 'inception_3b_1x1_bn',\n",
    "  'inception_3c_3x3_conv1', 'inception_3c_3x3_conv2', 'inception_3c_3x3_bn1', 'inception_3c_3x3_bn2',\n",
    "  'inception_3c_5x5_conv1', 'inception_3c_5x5_conv2', 'inception_3c_5x5_bn1', 'inception_3c_5x5_bn2',\n",
    "  'inception_4a_3x3_conv1', 'inception_4a_3x3_conv2', 'inception_4a_3x3_bn1', 'inception_4a_3x3_bn2',\n",
    "  'inception_4a_5x5_conv1', 'inception_4a_5x5_conv2', 'inception_4a_5x5_bn1', 'inception_4a_5x5_bn2',\n",
    "  'inception_4a_pool_conv', 'inception_4a_pool_bn',\n",
    "  'inception_4a_1x1_conv', 'inception_4a_1x1_bn',\n",
    "  'inception_4e_3x3_conv1', 'inception_4e_3x3_conv2', 'inception_4e_3x3_bn1', 'inception_4e_3x3_bn2',\n",
    "  'inception_4e_5x5_conv1', 'inception_4e_5x5_conv2', 'inception_4e_5x5_bn1', 'inception_4e_5x5_bn2',\n",
    "  'inception_5a_3x3_conv1', 'inception_5a_3x3_conv2', 'inception_5a_3x3_bn1', 'inception_5a_3x3_bn2',\n",
    "  'inception_5a_pool_conv', 'inception_5a_pool_bn',\n",
    "  'inception_5a_1x1_conv', 'inception_5a_1x1_bn',\n",
    "  'inception_5b_3x3_conv1', 'inception_5b_3x3_conv2', 'inception_5b_3x3_bn1', 'inception_5b_3x3_bn2',\n",
    "  'inception_5b_pool_conv', 'inception_5b_pool_bn',\n",
    "  'inception_5b_1x1_conv', 'inception_5b_1x1_bn',\n",
    "  'dense_layer'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Following the Paper from inception module\n",
    "\n",
    "# The first three layers are the simple conv layer followed \n",
    "    # conv -> Maxpool -> BN -> conv -> conv -> BN -> Maxpool\n",
    "# Now the inception bloacks starts\n",
    "    # Block = Layer1 [1x1, 1x1, Maxpool], Layer2 [1x1, 3x3, 5x5, 1x1]\n",
    "    # 2* [Block -> concat] -> Maxpool     \n",
    "    # 5 * [Block -> concat] -> Maxpool\n",
    "    # 2* [Block -> concat] -> Maxpool \n",
    "    \n",
    "# The Facenet model have a slightly different architecture when compared to inception modules\n",
    "convShape = {\n",
    "    'conv1': [64, 3, 7, 7],\n",
    "    'conv2': [64, 64, 1, 1],\n",
    "    'conv3': [192, 64, 3, 3],\n",
    "# Block 1\n",
    "    # Chain 1\n",
    "    'inception_3a_1x1_conv': [64, 192, 1, 1],\n",
    "    # Chain 2\n",
    "    'inception_3a_3x3_conv1': [96, 192, 1, 1],\n",
    "    'inception_3a_3x3_conv2': [128, 96, 3, 3],\n",
    "    # Chain 3\n",
    "    'inception_3a_5x5_conv1': [16, 192, 1, 1],\n",
    "    'inception_3a_5x5_conv2': [32, 16, 5, 5],\n",
    "    # Chain 4\n",
    "    'inception_3a_pool_conv': [32, 192, 1, 1],\n",
    "   \n",
    "# Block 2\n",
    "    # Chain 1\n",
    "    'inception_3b_1x1_conv': [64, 256, 1, 1],\n",
    "    # Chain 2\n",
    "    'inception_3b_3x3_conv1': [96, 256, 1, 1],\n",
    "    'inception_3b_3x3_conv2': [128, 96, 3, 3],\n",
    "    # Chain 3\n",
    "    'inception_3b_5x5_conv1': [32, 256, 1, 1],\n",
    "    'inception_3b_5x5_conv2': [64, 32, 5, 5],\n",
    "    # Chain 4\n",
    "    'inception_3b_pool_conv': [64, 256, 1, 1],\n",
    "   \n",
    "# Block 3  [Note: No chain 1 and 4]\n",
    "    # Chain 2\n",
    "    'inception_3c_3x3_conv1': [128, 320, 1, 1],\n",
    "    'inception_3c_3x3_conv2': [256, 128, 3, 3],\n",
    "    # Chain 3 : \n",
    "    'inception_3c_5x5_conv1': [32, 320, 1, 1],\n",
    "    'inception_3c_5x5_conv2': [64, 32, 5, 5],\n",
    "\n",
    "# Block 4\n",
    "    # Chain 1\n",
    "    'inception_4a_1x1_conv': [256, 640, 1, 1],\n",
    "    # Chain 2\n",
    "    'inception_4a_3x3_conv1': [96, 640, 1, 1],\n",
    "    'inception_4a_3x3_conv2': [192, 96, 3, 3],\n",
    "    # Chain 3\n",
    "    'inception_4a_5x5_conv1': [32, 640, 1, 1,],\n",
    "    'inception_4a_5x5_conv2': [64, 32, 5, 5],\n",
    "    # Chain 4 \n",
    "    'inception_4a_pool_conv': [128, 640, 1, 1],\n",
    "\n",
    "# Block 5\n",
    "    # Chain 2\n",
    "    'inception_4e_3x3_conv1': [160, 640, 1, 1],\n",
    "    'inception_4e_3x3_conv2': [256, 160, 3, 3],\n",
    "    # Chain 3\n",
    "    'inception_4e_5x5_conv1': [64, 640, 1, 1],\n",
    "    'inception_4e_5x5_conv2': [128, 64, 5, 5],\n",
    "\n",
    "# Block 6\n",
    "    # Chain 1\n",
    "    'inception_5a_1x1_conv': [256, 1024, 1, 1],\n",
    "    # Chain 2\n",
    "    'inception_5a_3x3_conv1': [96, 1024, 1, 1],\n",
    "    'inception_5a_3x3_conv2': [384, 96, 3, 3],\n",
    "    # Chain 3\n",
    "    'inception_5a_pool_conv': [96, 1024, 1, 1],\n",
    "  \n",
    "# Bloack 7\n",
    "    # Chain 1\n",
    "    'inception_5b_1x1_conv': [256, 736, 1, 1],\n",
    "    # Chain 2\n",
    "    'inception_5b_3x3_conv1': [96, 736, 1, 1],\n",
    "    'inception_5b_3x3_conv2': [384, 96, 3, 3],\n",
    "    # Chain 3\n",
    "    'inception_5b_pool_conv': [96, 736, 1, 1],\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parentPath = \"/Users/sam/All-Program/App-DataSet/Deep-Neural-Nets/Models/FaceNet-Inception/\"\n",
    "pathDict = {}\n",
    "for filename in os.listdir(parentPath): \n",
    "    if filename.endswith('.csv'):\n",
    "        pathDict[filename.replace('.csv', '') ] =  os.path.join(parentPath, filename)\n",
    "# pathDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "########## Rough\n",
    "# moduleName = ['inception_3a_1x1_conv', 'inception_3a_1x1_bn',\n",
    "#                'inception_3a_3x3_conv1', 'inception_3a_3x3_bn1',\n",
    "#                'inception_3a_3x3_conv2', 'inception_3a_3x3_bn2',\n",
    "#                'inception_3a_5x5_conv1', 'inception_3a_5x5_bn1',\n",
    "#                'inception_3a_5x5_conv2', 'inception_3a_5x5_bn2',\n",
    "#                'inception_3a_pool_conv', 'inception_3a_pool_bn']\n",
    "\n",
    "########## Rough\n",
    "\n",
    "\n",
    "moduleWeightDict = defaultdict(lambda: defaultdict())\n",
    "\n",
    "for num, name in enumerate(moduleName):\n",
    "    if 'conv' in name:\n",
    "        conv_w = np.genfromtxt(pathDict[name + '_w'], delimiter=',', dtype=None)\n",
    "        conv_w = np.reshape(conv_w, convShape[name])\n",
    "        # Transpose the weight shape to [filterX, filterY, inpChannels, outChannels]\n",
    "        conv_w = np.transpose(conv_w, (2, 3, 1, 0))\n",
    "        conv_b = np.genfromtxt(pathDict[name + '_b'], delimiter=',', dtype=None)\n",
    "        \n",
    "        moduleWeightDict[name]['w'] =  conv_w\n",
    "        moduleWeightDict[name]['b'] =  conv_b\n",
    "    elif 'bn' in name:\n",
    "            moduleWeightDict[name]['w'] = np.genfromtxt(pathDict[name + '_w'], delimiter=',', dtype=None)\n",
    "            moduleWeightDict[name]['b'] = np.genfromtxt(pathDict[name + '_b'], delimiter=',', dtype=None)\n",
    "            moduleWeightDict[name]['m'] = np.genfromtxt(pathDict[name + '_m'], delimiter=',', dtype=None)\n",
    "            moduleWeightDict[name]['v'] = np.genfromtxt(pathDict[name + '_v'], delimiter=',', dtype=None)\n",
    "    elif 'dense' in name:\n",
    "        dense_w = np.genfromtxt(parentPath+'/dense_w.csv', delimiter=',', dtype=None)\n",
    "        dense_w = np.reshape(dense_w, (128, 736))\n",
    "        dense_w = np.transpose(dense_w, (1, 0))\n",
    "        moduleWeightDict[name]['w'] = dense_w\n",
    "        moduleWeightDict[name]['b'] = np.genfromtxt(parentPath+'/dense_b.csv', delimiter=',', dtype=None)\n",
    "    else:\n",
    "        print ('OOPS! Something seems weird')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conv1', 'bn1', 'conv2', 'bn2', 'conv3', 'bn3', 'inception_3a_1x1_conv', 'inception_3a_1x1_bn', 'inception_3a_pool_conv', 'inception_3a_pool_bn', 'inception_3a_5x5_conv1', 'inception_3a_5x5_conv2', 'inception_3a_5x5_bn1', 'inception_3a_5x5_bn2', 'inception_3a_3x3_conv1', 'inception_3a_3x3_conv2', 'inception_3a_3x3_bn1', 'inception_3a_3x3_bn2', 'inception_3b_3x3_conv1', 'inception_3b_3x3_conv2', 'inception_3b_3x3_bn1', 'inception_3b_3x3_bn2', 'inception_3b_5x5_conv1', 'inception_3b_5x5_conv2', 'inception_3b_5x5_bn1', 'inception_3b_5x5_bn2', 'inception_3b_pool_conv', 'inception_3b_pool_bn', 'inception_3b_1x1_conv', 'inception_3b_1x1_bn', 'inception_3c_3x3_conv1', 'inception_3c_3x3_conv2', 'inception_3c_3x3_bn1', 'inception_3c_3x3_bn2', 'inception_3c_5x5_conv1', 'inception_3c_5x5_conv2', 'inception_3c_5x5_bn1', 'inception_3c_5x5_bn2', 'inception_4a_3x3_conv1', 'inception_4a_3x3_conv2', 'inception_4a_3x3_bn1', 'inception_4a_3x3_bn2', 'inception_4a_5x5_conv1', 'inception_4a_5x5_conv2', 'inception_4a_5x5_bn1', 'inception_4a_5x5_bn2', 'inception_4a_pool_conv', 'inception_4a_pool_bn', 'inception_4a_1x1_conv', 'inception_4a_1x1_bn', 'inception_4e_3x3_conv1', 'inception_4e_3x3_conv2', 'inception_4e_3x3_bn1', 'inception_4e_3x3_bn2', 'inception_4e_5x5_conv1', 'inception_4e_5x5_conv2', 'inception_4e_5x5_bn1', 'inception_4e_5x5_bn2', 'inception_5a_3x3_conv1', 'inception_5a_3x3_conv2', 'inception_5a_3x3_bn1', 'inception_5a_3x3_bn2', 'inception_5a_pool_conv', 'inception_5a_pool_bn', 'inception_5a_1x1_conv', 'inception_5a_1x1_bn', 'inception_5b_3x3_conv1', 'inception_5b_3x3_conv2', 'inception_5b_3x3_bn1', 'inception_5b_3x3_bn2', 'inception_5b_pool_conv', 'inception_5b_pool_bn', 'inception_5b_1x1_conv', 'inception_5b_1x1_bn', 'dense_layer'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moduleWeightDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7, 3, 64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moduleWeightDict[\"conv1\"]['w'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "dirPath = '/Users/sam/All-Program/App-DataSet/Deep-Neural-Nets/Models/FaceRecognition/train_happy.h5'\n",
    "\n",
    "train_dataset = h5py.File(dirPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['list_classes', 'train_set_x', 'train_set_y'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"train_set_x\": shape (600, 64, 64, 3), type \"|u1\">"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['train_set_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_dataset[\"train_set_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array(train_dataset['train_set_x'])[0]\n",
    "b = np.array(train_dataset['train_set_x'])[3]\n",
    "c = np.array(train_dataset['train_set_x'])[5]\n",
    "d = np.array(train_dataset['train_set_x'])[6]\n",
    "e = np.array(train_dataset['train_set_x'])[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot a image from the train data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "--> Store per person encoding in DataBase, by passing \n",
    "    all the image one by one to the \"img_to_encoding\" funciton\n",
    "\n",
    "Steps:\n",
    "    1. First get a model prepared using Keras, \"faceRecoModel\"\n",
    "    2. Write the Triplet loss function \n",
    "    3. Add the triplet loss function as an optimization to the network.\n",
    "    4. Load trained weight from FaceNet \"load_weights_from_FaceNet\"\n",
    "    5. For a new image let the network pass throught the FaceNet model and output encoding \"img_to_encoding\"\n",
    "    6. Compare the encoding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
