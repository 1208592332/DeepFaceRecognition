{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy import genfromtxt\n",
    "\n",
    "# from keras import backend as K\n",
    "# from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "# from keras.models import Model\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "# from keras.layers.core import Lambda, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Following the Paper from inception module\n",
    "\n",
    "# The first three layers are the simple conv layer followed \n",
    "    # conv -> Maxpool -> BN -> conv -> conv -> BN -> Maxpool\n",
    "# Now the inception bloacks starts\n",
    "    # Block = Layer1 [1x1, 1x1, Maxpool], Layer2 [1x1, 3x3, 5x5, 1x1]\n",
    "    # 2* [Block -> concat] -> Maxpool     \n",
    "    # 5 * [Block -> concat] -> Maxpool\n",
    "    # 2* [Block -> concat] -> Maxpool \n",
    "    \n",
    "    \n",
    "# The Facenet model have a slightly different architecture when compared to inception modules\n",
    "convShape = {\n",
    "    'conv1': [64, 3, 7, 7],\n",
    "    'conv2': [64, 64, 1, 1],\n",
    "    'conv3': [192, 64, 3, 3],\n",
    "# Block 1\n",
    "    # Chain 1\n",
    "    'inception_3a_1x1_conv': [64, 192, 1, 1],\n",
    "    # Chain 2\n",
    "    'inception_3a_3x3_conv1': [96, 192, 1, 1],\n",
    "    'inception_3a_3x3_conv2': [128, 96, 3, 3],\n",
    "    # Chain 3\n",
    "    'inception_3a_5x5_conv1': [16, 192, 1, 1],\n",
    "    'inception_3a_5x5_conv2': [32, 16, 5, 5],\n",
    "    # Chain 4\n",
    "    'inception_3a_pool_conv': [32, 192, 1, 1],\n",
    "   \n",
    "# Block 2\n",
    "    # Chain 1\n",
    "    'inception_3b_1x1_conv': [64, 256, 1, 1],\n",
    "    # Chain 2\n",
    "    'inception_3b_3x3_conv1': [96, 256, 1, 1],\n",
    "    'inception_3b_3x3_conv2': [128, 96, 3, 3],\n",
    "    # Chain 3\n",
    "    'inception_3b_5x5_conv1': [32, 256, 1, 1],\n",
    "    'inception_3b_5x5_conv2': [64, 32, 5, 5],\n",
    "    # Chain 4\n",
    "    'inception_3b_pool_conv': [64, 256, 1, 1],\n",
    "   \n",
    "# Block 3  [Note: No chain 1 and 4]\n",
    "    # Chain 2\n",
    "    'inception_3c_3x3_conv1': [128, 320, 1, 1],\n",
    "    'inception_3c_3x3_conv2': [256, 128, 3, 3],\n",
    "    # Chain 3 : \n",
    "    'inception_3c_5x5_conv1': [32, 320, 1, 1],\n",
    "    'inception_3c_5x5_conv2': [64, 32, 5, 5],\n",
    "\n",
    "# Block 4\n",
    "    # Chain 1\n",
    "    'inception_4a_1x1_conv': [256, 640, 1, 1],\n",
    "    # Chain 2\n",
    "    'inception_4a_3x3_conv1': [96, 640, 1, 1],\n",
    "    'inception_4a_3x3_conv2': [192, 96, 3, 3],\n",
    "    # Chain 3\n",
    "    'inception_4a_5x5_conv1': [32, 640, 1, 1,],\n",
    "    'inception_4a_5x5_conv2': [64, 32, 5, 5],\n",
    "    # Chain 4 \n",
    "    'inception_4a_pool_conv': [128, 640, 1, 1],\n",
    "\n",
    "# Block 5\n",
    "    # Chain 2\n",
    "    'inception_4e_3x3_conv1': [160, 640, 1, 1],\n",
    "    'inception_4e_3x3_conv2': [256, 160, 3, 3],\n",
    "    # Chain 3\n",
    "    'inception_4e_5x5_conv1': [64, 640, 1, 1],\n",
    "    'inception_4e_5x5_conv2': [128, 64, 5, 5],\n",
    "\n",
    "# Block 6\n",
    "    # Chain 1\n",
    "    'inception_5a_1x1_conv': [256, 1024, 1, 1],\n",
    "    # Chain 2\n",
    "    'inception_5a_3x3_conv1': [96, 1024, 1, 1],\n",
    "    'inception_5a_3x3_conv2': [384, 96, 3, 3],\n",
    "    # Chain 3\n",
    "    'inception_5a_pool_conv': [96, 1024, 1, 1],\n",
    "  \n",
    "# Bloack 7\n",
    "    # Chain 1\n",
    "    'inception_5b_1x1_conv': [256, 736, 1, 1],\n",
    "    # Chain 2\n",
    "    'inception_5b_3x3_conv1': [96, 736, 1, 1],\n",
    "    'inception_5b_3x3_conv2': [384, 96, 3, 3],\n",
    "    # Chain 3\n",
    "    'inception_5b_pool_conv': [96, 736, 1, 1],\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "picPath = '/Users/sam/All-Program/App-DataSet/Deep-Neural-Nets/Models/FaceRecognition/camera_0.jpg'\n",
    "\n",
    "from scipy import misc\n",
    "\n",
    "def readImage(imagePath):\n",
    "    '''\n",
    "        The input data is is in the shape of [nh, nw, nc], convert it to [nc, nh, nw]\n",
    "    '''\n",
    "    image = misc.imread(picPath)\n",
    "    \n",
    "    img = np.around(np.transpose(image, (2,0,1))/255.0, decimals=12) #(2,0,1) = [nc, nh, nw]\n",
    "    print (image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "picPath = '/Users/sam/All-Program/App-DataSet/Deep-Neural-Nets/Models/FaceRecognition/camera_0.jpg'\n",
    "\n",
    "from scipy import misc\n",
    "\n",
    "def readImage(imagePath):\n",
    "    '''\n",
    "        The input data is is in the shape of [nh, nw, nc], convert it to [nc, nh, nw]\n",
    "    '''\n",
    "    image = misc.imread(picPath)\n",
    "    \n",
    "    img = np.around(image/255.0, decimals=12) #(2,0,1) = [nc, nh, nw]\n",
    "    print (image.shape)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "(7, 7, 3, 64)\n",
      "(64,)\n",
      "conv2\n",
      "(1, 1, 64, 64)\n",
      "(64,)\n",
      "conv3\n",
      "(3, 3, 64, 192)\n",
      "(192,)\n",
      "bn1\n",
      "(64,) (64,) (64,) (64,)\n",
      "bn2\n",
      "(64,) (64,) (64,) (64,)\n",
      "bn3\n",
      "(192,) (192,) (192,) (192,)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "moduleWeightDict = defaultdict(lambda: defaultdict())\n",
    "parentPath = \"/Users/sam/All-Program/App-DataSet/Deep-Neural-Nets/Models/FaceNet-Inception\"\n",
    "layer_name = ['conv1', 'conv2', 'conv3', \n",
    "              'bn1','bn2', 'bn3',\n",
    "#               'inception_3a_1x1_conv', \n",
    "#               'inception_3a_3x3_conv1',\n",
    "#               'inception_3a_3x3_conv2',\n",
    "#               'inception_3a_5x5_conv1', \n",
    "#               'inception_3a_5x5_conv2', \n",
    "#               'inception_3a_pool_conv',\n",
    "#               'inception_3b_1x1_conv', \n",
    "#               'inception_3b_3x3_conv1', \n",
    "#               'inception_3b_3x3_conv2',\n",
    "#               'inception_3b_5x5_conv1', \n",
    "#               'inception_3b_5x5_conv2', \n",
    "#               'inception_3b_pool_conv',\n",
    "#               'inception_3c_3x3_conv1',\n",
    "#               'inception_3c_3x3_conv2',\n",
    "#               'inception_3c_5x5_conv1', \n",
    "#               'inception_3c_5x5_conv2',\n",
    "#               'inception_4a_3x3_conv1', \n",
    "#               'inception_4a_3x3_conv2', \n",
    "#               'inception_4a_5x5_conv1', \n",
    "#               'inception_4a_5x5_conv2', \n",
    "#               'inception_4a_pool_conv', \n",
    "#               'inception_4a_1x1_conv',\n",
    "#               'inception_4e_3x3_conv1',\n",
    "#               'inception_4e_3x3_conv2',\n",
    "#               'inception_4e_5x5_conv1', \n",
    "#               'inception_4e_5x5_conv2',\n",
    "#               'inception_5a_1x1_conv',\n",
    "#               'inception_5a_3x3_conv1',\n",
    "#               'inception_5a_3x3_conv2',\n",
    "#               'inception_5a_pool_conv',\n",
    "#               'inception_5b_3x3_conv1',\n",
    "#               'inception_5b_3x3_conv2',\n",
    "#               'inception_5b_pool_conv',\n",
    "#               'inception_5b_1x1_conv',\n",
    "              'dense']#, 'conv1_w']\n",
    "\n",
    "for name in layer_name:\n",
    "    if 'conv' in name:\n",
    "        conv1_w = np.genfromtxt(parentPath+\"/\"+name+'_w.csv', delimiter=',', dtype=None)\n",
    "        conv1_w = np.reshape(conv1_w, convShape[name])\n",
    "        conv1_w = np.transpose(conv1_w, (2, 3, 1, 0))\n",
    "        conv1_b = np.genfromtxt(parentPath+\"/\"+name+'_b.csv', delimiter=',', dtype=None)\n",
    "        moduleWeightDict[name]['w'] = conv1_w\n",
    "        moduleWeightDict[name]['b'] = conv1_b\n",
    "        print (name)\n",
    "        print (conv1_w.shape)\n",
    "        print (conv1_b.shape)\n",
    "    elif 'dense' in name:\n",
    "        dense_w = np.genfromtxt(parentPath+\"/\"+name+'_w.csv', delimiter=',', dtype=None)\n",
    "        dense_w = np.reshape(dense_w, (128,736)) # Remember the input weights are in reverse order\n",
    "        dense_w = np.transpose(dense_w, (1,0))   # Transpose the input to accept as (layer_l, layer_l+1)\n",
    "        dense_b = np.genfromtxt(parentPath+\"/\"+name+'_b.csv', delimiter=',', dtype=None)\n",
    "        moduleWeightDict[name]['w'] = dense_w\n",
    "        moduleWeightDict[name]['b'] = dense_b\n",
    "    elif 'bn' in name:\n",
    "        bn_w = genfromtxt(parentPath+\"/\"+name+'_w.csv', delimiter=',', dtype=None)\n",
    "        bn_b = genfromtxt(parentPath+\"/\"+name+'_b.csv', delimiter=',', dtype=None)\n",
    "        bn_m = genfromtxt(parentPath+\"/\"+name+'_m.csv', delimiter=',', dtype=None)\n",
    "        bn_v = genfromtxt(parentPath+\"/\"+name+'_v.csv', delimiter=',', dtype=None)\n",
    "        print (name)\n",
    "        print (bn_w.shape, bn_b.shape, bn_m.shape, bn_v.shape)\n",
    "    \n",
    "# FRmodel.get_layer('conv1').set_weights([conv1_w, conv1_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "pop_mean = tf.Variable(tf.zeros([tf.cast(moduleWeightDict[\"conv1\"][\"w\"], dtype=tf.float32).get_shape()[-1]]), \n",
    "                       trainable=False)\n",
    "print (pop_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/App-Setup/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 3)\n",
      "inpTensor  (?, 96, 96, 3)\n",
      "conv1:  (?, 48, 48, 64)\n",
      "conv1 Zero-Padding + MAXPOOL  (?, 50, 50, 64)\n",
      "conv1 Zero-Padding + MAXPOOL  (?, 24, 24, 64)\n",
      "conv2:  (?, 24, 24, 64)\n",
      "conv2 Zero-Padding + MAXPOOL  (?, 26, 26, 64)\n",
      "conv3:  (?, 24, 24, 192)\n",
      "conv3 Zero-Padding + MAXPOOL  (?, 26, 26, 192)\n",
      "conv3 Zero-Padding + MAXPOOL  (?, 12, 12, 192)\n",
      "Chain 2:  (?, 12, 12, 128)\n",
      "Chain 3:  (?, 12, 12, 32)\n",
      "Chain 4:  (?, 12, 12, 32)\n",
      "Chain 1:  (?, 12, 12, 64)\n",
      "inception3a:  (?, 12, 12, 256)\n",
      "Chain 2:  (?, 12, 12, 128)\n",
      "Chain 3:  (?, 12, 12, 64)\n",
      "Chain 4:  (?, 12, 12, 64)\n",
      "Chain 1:  (?, 12, 12, 64)\n",
      "inception3b:  (?, 12, 12, 320)\n",
      "Chain 2:  (?, 6, 6, 256)\n",
      "Chain 3:  (?, 6, 6, 64)\n",
      "Chain 4:  (?, 6, 6, 320)\n",
      "inception3c:  (?, 6, 6, 640)\n",
      "Inside Inception module1:  (?, 6, 6, 640)\n",
      "Chain 2:  (?, 6, 6, 192)\n",
      "Chain 3:  (?, 6, 6, 64)\n",
      "Chain 4:  (?, 6, 6, 128)\n",
      "Chain 1:  (?, 6, 6, 256)\n",
      "inception4a:  (?, 6, 6, 640)\n",
      "Inside Inception module1:  (?, 6, 6, 640)\n",
      "Chain 2:  (?, 3, 3, 256)\n",
      "Chain 3:  (?, 3, 3, 128)\n",
      "Chain 4:  (?, 3, 3, 640)\n",
      "inception4e:  (?, 3, 3, 1024)\n",
      "Inside Inception module1:  (?, 3, 3, 1024)\n",
      "Chain 2:  (?, 3, 3, 384)\n",
      "Chain 4:  (?, 3, 3, 96)\n",
      "Chain 1:  (?, 3, 3, 256)\n",
      "inception5a:  (?, 3, 3, 736)\n",
      "Inside Inception module1:  (?, 3, 3, 736)\n",
      "Chain 2:  (?, 3, 3, 384)\n",
      "Chain 4:  (?, 3, 3, 96)\n",
      "Chain 1:  (?, 3, 3, 256)\n",
      "inception5b:  (?, 3, 3, 736)\n",
      "X after FC pool:  (?, 1, 1, 736)\n",
      "X after X Flattened:  (?, 736)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Input 'b' of 'MatMul' Op has type float64 that does not match type float32 of argument 'a'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Users/sam/App-Setup/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    491\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[0;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         % (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[1;32m    550\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype float32 for Tensor with dtype float64: 'Tensor(\"InceptionFC/MatMul/b:0\", shape=(736, 128), dtype=float64)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-707d995423ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mreset_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtensorDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmoduleWeightDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#(img, conv1_w, conv1_b, s=2, pad='SAME',  scope_name='conv1', isTrainable=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/sam/All-Program/App/DeepFaceRecognition/nn/Network.py\u001b[0m in \u001b[0;36mgetModel\u001b[0;34m(imgShape, params)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minception5a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minception5b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullyConnected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpTensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minpTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/All-Program/App/DeepFaceRecognition/nn/Model.py\u001b[0m in \u001b[0;36mfullyConnected\u001b[0;34m(X, params)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X after X Flattened: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dense'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dense'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X after FC Matmul: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[0;32m-> 1844\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   1287\u001b[0m   \"\"\"\n\u001b[1;32m   1288\u001b[0m   result = _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\n\u001b[0;32m-> 1289\u001b[0;31m                                 transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1290\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    524\u001b[0m                   \u001b[0;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[0;32m--> 526\u001b[0;31m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'b' of 'MatMul' Op has type float64 that does not match type float32 of argument 'a'."
     ]
    }
   ],
   "source": [
    "from Network import getModel\n",
    "\n",
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "img = readImage(picPath)\n",
    "# img = np.reshape(img, (1,img.shape[0], img.shape[1], img.shape[2]))\n",
    "img.shape\n",
    "reset_graph()\n",
    "tensorDict = getModel(img.shape, params=moduleWeightDict)#(img, conv1_w, conv1_b, s=2, pad='SAME',  scope_name='conv1', isTrainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 3)\n",
      "inpTensor  (?, 96, 96, 3)\n",
      "conv1:  (?, 48, 48, 64)\n",
      "conv1 Zero-Padding + MAXPOOL  (?, 50, 50, 64)\n",
      "conv1 Zero-Padding + MAXPOOL  (?, 24, 24, 64)\n",
      "conv2:  (?, 24, 24, 64)\n",
      "conv2 Zero-Padding + MAXPOOL  (?, 26, 26, 64)\n",
      "conv3:  (?, 24, 24, 192)\n",
      "conv3 Zero-Padding + MAXPOOL  (?, 26, 26, 192)\n",
      "conv3 Zero-Padding + MAXPOOL  (?, 12, 12, 192)\n",
      "Inside Inception module1:  (?, 12, 12, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/App-Setup/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain 2:  (?, 12, 12, 128)\n",
      "Chain 3:  (?, 12, 12, 32)\n",
      "Chain 4:  (?, 12, 12, 32)\n",
      "Chain 1:  (?, 12, 12, 64)\n",
      "inception3a:  (?, 12, 12, 256)\n",
      "Inside Inception module1:  (?, 12, 12, 256)\n",
      "Chain 2:  (?, 12, 12, 128)\n",
      "Chain 3:  (?, 12, 12, 64)\n",
      "Chain 4:  (?, 12, 12, 64)\n",
      "Chain 1:  (?, 12, 12, 64)\n",
      "inception3b:  (?, 12, 12, 320)\n"
     ]
    }
   ],
   "source": [
    "from nn.Inception import getModel\n",
    "\n",
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "img = readImage(picPath)\n",
    "# img = np.reshape(img, (1,img.shape[0], img.shape[1], img.shape[2]))\n",
    "img.shape\n",
    "reset_graph()\n",
    "tensorDict = getModel(img.shape, params=moduleWeightDict)#(img, conv1_w, conv1_b, s=2, pad='SAME',  scope_name='conv1', isTrainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "#     print (img.shape)\n",
    "    img1 = np.reshape(img, (1,img.shape[0], img.shape[1], img.shape[2]))\n",
    "    print (img1.shape)\n",
    "    x = sess.run([tensorDict['output']], feed_dict={tensorDict['inpTensor']:img1})\n",
    "    print (x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
