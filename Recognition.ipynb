{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from data_transformer.data_formatter import DataFormatter\n",
    "from data_transformer.preprocess import Preprocessing\n",
    "\n",
    "from data_transformer.data_prep import DataIO, genDistinctStratifiedBatches, genRandomStratifiedBatches\n",
    "from nn.load_params import layer_name, convShape, getWeights\n",
    "from nn.utils import getTriplets, tripletLoss\n",
    "from train_test.model import *\n",
    "from config import path_dict\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logfile.log\", filemode=\"w\",\n",
    "                    format=\"%(asctime)-15s %(levelname)-8s %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE TIME RUN: \n",
    "------------\n",
    "#### INPUT :  Folder path with images of several people, ensure the image folders are named with the person name\n",
    "#### OUTPUT: Dumps a pickle file with three keys, dataX, dataY, labelDict. \n",
    "            * dataX: images converted into nd array\n",
    "            * dataY: for each record of nd array, Labels are numerical (1,2,3,4,5)\n",
    "            * labelDict: Contains the label corresponding to person name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training = True\n",
    "# verification = True\n",
    "\n",
    "# if training:\n",
    "#     objDP = DataFormatter(path_dict['parent_path'], 'training')\n",
    "#     objDP.createResizedData()\n",
    "#     dataX, dataY, labelDict = objDP.imageToArray()\n",
    "#     DataFormatter.dumpPickleFile(dataX, dataY, labelDict,\n",
    "#                                folderPath=os.path.join(path_dict['data_model_path']),\n",
    "#                                picklefileName='training_imgarr.pickle')\n",
    "# if verification:\n",
    "#     objDP = DataFormatter(path_dict['parent_path'], 'verification')\n",
    "#     objDP.createResizedData()\n",
    "#     dataX, dataY, labelDict = objDP.imageToArray()\n",
    "#     DataFormatter.dumpPickleFile(dataX, dataY, labelDict,\n",
    "#                                folderPath=os.path.join(path_dict['data_model_path']),\n",
    "#                                picklefileName='verification_imgarr.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE RANDOM BATCHES:\n",
    "----------------\n",
    "#### INPUT: Image nd array as input  [num_images, imgX, imgY, num_channels]\n",
    "#### OUTPUT: Outputs a pickle file with shape [num_batches, num_image_per_batch, imgX, imgY, num_channels]\n",
    "\n",
    "       *  We would wanna do stocastic descent for minibatches and update the parameters perbatch. This module attempts to create stratified batches (each batch would have equal distribution of labels). \n",
    "       \n",
    "       * when genDistinctStratifiedBatches. The images in the batched would be distinct (would not repeat)\n",
    "       * when genRandomStratifiedBatches. No seed is set for shuffling. So Images in different batches may repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# debugg = True\n",
    "# numImgsPerLabels = 60 # num image per label per batch\n",
    "# numBatches = 10\n",
    "# if debugg:\n",
    "#     trainX, trainY, trainLabelDict = DataIO.getPickleFile(path_dict['data_model_path'],\n",
    "#                                                                  'training_imgarr.pickle')\n",
    "#     verX, verY, verLabelDict = DataIO.getPickleFile(path_dict['data_model_path'],\n",
    "#                                                            'verification_imgarr.pickle')\n",
    "#     print(trainX.shape, trainY.shape)\n",
    "#     print(verX.shape, verY.shape)\n",
    "#     genDistinctStratifiedBatches(trainX, trainY, numImgsPerLabels=numImgsPerLabels, numBatches=numBatches,\n",
    "#                           fileName='distinct_stratified_batches.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## RESET TENSORFLOW GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET INCEPTION WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "moduleWeightDict = getWeights(path_dict['inception_nn4small_weights_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO's:\n",
    "\n",
    "1. Remove the random weight initialiazer for the last layer, and initialize it \n",
    "   with the inception net weights.  **DONE**\n",
    "\n",
    "2. implement a module to save weights as checkpoints to the disk.  **DONE**\n",
    "\n",
    "3. create a function to toggle between Random weight initializer, Inception net weight initializer \n",
    "   and using the saved checkpoint for the last Inception layer. **DONE**\n",
    "   \n",
    "4.0 : REMEBER TO STORE THE exponential weighted average of mean and variable in the batch normalization \n",
    "      fine tune function. SET THESE AS A VARIABLE (LOOK AT CIFAR CODE FOR HELP)\n",
    " \n",
    "4. Add more images. **DONE**\n",
    "\n",
    "5. Create a complete workflow train the network and perform cross validation: **DONE**\n",
    "\n",
    "6. Store 1 image encodings for the 3-4 labels you have.\n",
    "\n",
    "7. For a new image, pass the image throught network, get the encoding and see which is the most closest face using the encoding from the step 6.\n",
    "\n",
    "8. Try :\n",
    "    1. SVM classfication on embedding feature space: Get cross validation accuracy: **DONE**\n",
    "    2. Softmax classification on embedding feature space: Get cross validation accuracy. \n",
    "    \n",
    "9. The triplet selection now has, random selection of Hard negative. Having random selection makes it difficult to adjust parameters. So make is generated by a sedd, but the sees itself should be generated randomly via a different sees. Since having the same seeed decide a triplet would be problematic becasue the same hard negative would always be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class SVM():\n",
    "    '''\n",
    "    # The embeddings in a nutshell are features. The face image goes through a complex network and results in\n",
    "    # embeddings that captures complex features of a face. SVM's are good at classifying small datasets.\n",
    "    # SVM are also robust to over fitting. The idea here is that we would wanna learn a SVM classifier using the\n",
    "    # embeddings as the feature space and see for the given embedding, how many times we are able to predict the\n",
    "    # correct class\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, embeddings, labels, model_name=None):\n",
    "        '''\n",
    "        :param embeddings:   Embeddings of the image\n",
    "        :param labels:       labels\n",
    "        :return:\n",
    "        '''\n",
    "        model = SVC(kernel='linear', probability=True)\n",
    "        model.fit(embeddings, labels)\n",
    "        joblib.dump(model, os.path.join(path_dict['classification_model_path'], str(model_name)+\"_svm.sav\"))\n",
    "        \n",
    "    def classify(self, embeddings, model_name=None):\n",
    "        '''\n",
    "        :param embeddings: Image embeddings to classify\n",
    "        :param model_name:\n",
    "        :return:\n",
    "        '''\n",
    "        model = joblib.load(os.path.join(path_dict['classification_model_path'], str(model_name)+\"_svm.sav\"))\n",
    "        predLabels = model.predict_proba(embeddings)\n",
    "        top_label_idx = np.argmax(predLabels, axis=1)\n",
    "        labelProb = predLabels[np.arange(len(top_label_idx)), top_label_idx]\n",
    "        return top_label_idx, labelProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input data (X) is:  (10, 18, 96, 96, 3)\n",
      "The shape of input data (Y) is:  (10, 18)\n",
      "Unique labels in dataY is:  [ 0.  1.  2.]\n",
      "Label dict:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Epoch= 1, Loss= 8.480953\n",
      "Fold: 1, Epoch= 1, Loss= 8.935085\n",
      "Fold: 1, Epoch= 1, Loss= 9.947358\n",
      "Fold: 1, Epoch= 1, Loss= 7.424319\n",
      "Fold: 1, Epoch= 1, Loss= 8.629944\n",
      "Fold: 1, Epoch= 1, Loss= 8.571918\n",
      "Fold: 1, Epoch= 1, Loss= 8.388338\n",
      "Fold: 1, Epoch= 1, Loss= 8.538416\n",
      "Fold: 1, Epoch= 1, Loss= 8.515645\n",
      "0.148148148148\n",
      "0.222222222222\n",
      "Fold: 1, Epoch= 2, Loss= 4.066136\n",
      "Fold: 1, Epoch= 2, Loss= 8.714199\n",
      "Fold: 1, Epoch= 2, Loss= 8.788931\n",
      "Fold: 1, Epoch= 2, Loss= 6.727140\n",
      "Fold: 1, Epoch= 2, Loss= 6.352633\n",
      "Fold: 1, Epoch= 2, Loss= 6.901706\n",
      "Fold: 1, Epoch= 2, Loss= 8.173630\n",
      "Fold: 1, Epoch= 2, Loss= 7.169882\n",
      "Fold: 1, Epoch= 2, Loss= 6.928528\n",
      "0.240740740741\n",
      "0.277777777778\n",
      "Fold: 1, Epoch= 3, Loss= 5.994696\n",
      "Fold: 1, Epoch= 3, Loss= 6.961951\n",
      "Fold: 1, Epoch= 3, Loss= 6.893156\n",
      "Fold: 1, Epoch= 3, Loss= 6.350350\n",
      "Fold: 1, Epoch= 3, Loss= 6.565275\n",
      "Fold: 1, Epoch= 3, Loss= 4.420354\n",
      "Fold: 1, Epoch= 3, Loss= 7.104852\n",
      "Fold: 1, Epoch= 3, Loss= 4.362723\n",
      "Fold: 1, Epoch= 3, Loss= 6.949879\n",
      "0.0925925925926\n",
      "0.222222222222\n",
      "Fold: 1, Epoch= 4, Loss= 3.877691\n",
      "Fold: 1, Epoch= 4, Loss= 6.907005\n",
      "Fold: 1, Epoch= 4, Loss= 6.509748\n",
      "Fold: 1, Epoch= 4, Loss= 4.974575\n",
      "Fold: 1, Epoch= 4, Loss= 4.274404\n",
      "Fold: 1, Epoch= 4, Loss= 3.471547\n",
      "Fold: 1, Epoch= 4, Loss= 4.646661\n",
      "Fold: 1, Epoch= 4, Loss= 4.080897\n",
      "Fold: 1, Epoch= 4, Loss= 5.081177\n",
      "0.487654320988\n",
      "0.444444444444\n",
      "Fold: 1, Epoch= 5, Loss= 1.445346\n",
      "Fold: 1, Epoch= 5, Loss= 5.491865\n",
      "Fold: 1, Epoch= 5, Loss= 6.564331\n",
      "Fold: 1, Epoch= 5, Loss= 2.345203\n",
      "Fold: 1, Epoch= 5, Loss= 4.642584\n",
      "Fold: 1, Epoch= 5, Loss= 2.746866\n",
      "Fold: 1, Epoch= 5, Loss= 5.118132\n",
      "Fold: 1, Epoch= 5, Loss= 2.736776\n",
      "Fold: 1, Epoch= 5, Loss= 4.258371\n",
      "0.314814814815\n",
      "0.333333333333\n",
      "Fold: 1, Epoch= 6, Loss= 0.980874\n",
      "Fold: 1, Epoch= 6, Loss= 4.786376\n",
      "Fold: 1, Epoch= 6, Loss= 2.804216\n",
      "Fold: 1, Epoch= 6, Loss= 4.579950\n",
      "Fold: 1, Epoch= 6, Loss= 3.086884\n",
      "Fold: 1, Epoch= 6, Loss= 2.517078\n",
      "Fold: 1, Epoch= 6, Loss= 4.410371\n",
      "Fold: 1, Epoch= 6, Loss= 4.865468\n",
      "Fold: 1, Epoch= 6, Loss= 4.281737\n",
      "0.259259259259\n",
      "0.277777777778\n",
      "Fold: 1, Epoch= 7, Loss= 0.192583\n",
      "Fold: 1, Epoch= 7, Loss= 3.477328\n",
      "Fold: 1, Epoch= 7, Loss= 2.196874\n",
      "Fold: 1, Epoch= 7, Loss= 3.460026\n",
      "Fold: 1, Epoch= 7, Loss= 2.999078\n",
      "Fold: 1, Epoch= 7, Loss= 2.665817\n",
      "Fold: 1, Epoch= 7, Loss= 3.445969\n",
      "Fold: 1, Epoch= 7, Loss= 1.560043\n",
      "Fold: 1, Epoch= 7, Loss= 0.796881\n",
      "0.58024691358\n",
      "0.611111111111\n",
      "Fold: 1, Epoch= 8, Loss= 0.595237\n",
      "Fold: 1, Epoch= 8, Loss= 1.398524\n",
      "Fold: 1, Epoch= 8, Loss= 2.180910\n",
      "Fold: 1, Epoch= 8, Loss= 2.632124\n",
      "Fold: 1, Epoch= 8, Loss= 3.280628\n",
      "Fold: 1, Epoch= 8, Loss= 0.389080\n",
      "Fold: 1, Epoch= 8, Loss= 2.000452\n",
      "Fold: 1, Epoch= 8, Loss= 3.174375\n",
      "Fold: 1, Epoch= 8, Loss= 0.393354\n",
      "0.123456790123\n",
      "0.166666666667\n",
      "Fold: 1, Epoch= 9, Loss= 2.181999\n",
      "Fold: 1, Epoch= 9, Loss= 2.121850\n",
      "Fold: 1, Epoch= 9, Loss= 3.003785\n",
      "Fold: 1, Epoch= 9, Loss= 1.739830\n",
      "Fold: 1, Epoch= 9, Loss= 2.387426\n",
      "Fold: 1, Epoch= 9, Loss= 0.873711\n",
      "Fold: 1, Epoch= 9, Loss= 2.594828\n",
      "Fold: 1, Epoch= 9, Loss= 0.584808\n",
      "Fold: 1, Epoch= 9, Loss= 0.970905\n",
      "0.524691358025\n",
      "0.666666666667\n",
      "Fold: 1, Epoch= 10, Loss= 0.383759\n",
      "Fold: 1, Epoch= 10, Loss= 1.586863\n",
      "Fold: 1, Epoch= 10, Loss= 0.806332\n",
      "Fold: 1, Epoch= 10, Loss= 1.805517\n",
      "Fold: 1, Epoch= 10, Loss= 1.667612\n",
      "Fold: 1, Epoch= 10, Loss= 0.982321\n",
      "Fold: 1, Epoch= 10, Loss= 0.779763\n",
      "Fold: 1, Epoch= 10, Loss= 1.967456\n",
      "Fold: 1, Epoch= 10, Loss= 0.617002\n",
      "0.0987654320988\n",
      "0.166666666667\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from config import myNet\n",
    "\n",
    "which_file = 'distinct_stratified_batches.pickle'\n",
    "checkpoint_file_name = 'distinct_stratified_model'\n",
    "\n",
    "\n",
    "'''\n",
    "dataX = [num_batches, image_per_batch, image_x, image_y, image_channels]\n",
    "dataY = [num_batches, labels]\n",
    "\n",
    "'''\n",
    "\n",
    "class Execute():\n",
    "    def __init__(self, params, myNet, embeddingType='finetune'):\n",
    "        self.params = params\n",
    "        self.embeddingType = embeddingType\n",
    "        self.myNet = myNet\n",
    "        self.myNet['learning_rate'] = 0.0001\n",
    "        \n",
    "    def runPreprocessor(self, dataIN, sess):\n",
    "        preprocessedData = np.ndarray(shape=(dataIN.shape), dtype='float32')\n",
    "        for numImage in np.arange(dataIN.shape[0]):\n",
    "            feed_dict = {\n",
    "                self.preprocessGraphDict['imageIN']:dataIN[numImage,:]\n",
    "            }\n",
    "            preprocessedData[numImage,:] = sess.run(self.preprocessGraphDict['imageOUT'],\n",
    "                                                      feed_dict=feed_dict)\n",
    "        return preprocessedData\n",
    "        \n",
    "    def setNewWeights(self, sess):\n",
    "        logging.info('UPDATING WEITHGS WITH FINETUNED WEIGHTS .........')\n",
    "        trainableVars = tf.get_collection(ops.GraphKeys.TRAINABLE_VARIABLES)\n",
    "        if self.embeddingType=='finetune':\n",
    "            for var in trainableVars:\n",
    "                scope, name = var.name.split(':')[0].split('/')\n",
    "                if len(self.params[scope][name]) != 0:\n",
    "                    var_ = sess.run(var)\n",
    "                    logging.info('Updating param with scope %s and name %s and shape %s with shape %s',\n",
    "                                 str(scope), str(name), str(self.params[scope][name].shape), str(var_.shape))\n",
    "                    self.params[scope][name] = var_\n",
    "                else:\n",
    "                    raise ValueError('It seems that the scope %s or variable %s didnt exist in the dictionary ' % (str(scope), str(name)))\n",
    "    \n",
    "    def train(self, trnX_, trnY_, sess):\n",
    "        '''\n",
    "            1. Make the use of getEmbedding to get the graph with last layer parameter updated with the \n",
    "            fine tuned weights.\n",
    "            2. Get the new embedding for batch/epoch using the computation graph\n",
    "            3. Use the embeddings as feature for a classifier (svm/softmax)\n",
    "            4. Classify faces using the new embeddings.\n",
    "        '''\n",
    "        trainEmbedGraph = getEmbeddings([96,96,3], self.params)\n",
    "        embeddings = sess.run(trainEmbedGraph['output'], \n",
    "                              feed_dict={trainEmbedGraph['inpTensor']:trnX_})\n",
    "        logging.info('Training Embeddings shape %s', embeddings.shape)\n",
    "        obj_svm = SVM()\n",
    "        obj_svm.train(embeddings, labels=trnY_, \n",
    "                      model_name='nFold_%s_batch_%s'%(str(self.nFold),str(self.epoch)))\n",
    "        train_labels, train_label_prob = obj_svm.classify(embeddings, \n",
    "                                             model_name='nFold_%s_batch_%s'%(str(self.nFold),str(self.epoch)))\n",
    "        return train_labels, train_label_prob\n",
    "    \n",
    "    def cvalid(self, cvX_, sess):\n",
    "        embedGraph = getEmbeddings(myNet['image_shape'], self.params)\n",
    "        embeddings = sess.run(embedGraph['output'], \n",
    "                              feed_dict={embedGraph['inpTensor']:cvX_})\n",
    "        logging.info('Cross validation Embeddings shape %s', embeddings.shape)\n",
    "        obj_svm = SVM()\n",
    "        cv_labels, cv_label_prob = obj_svm.classify(embeddings, \n",
    "                                             model_name='nFold_%s_batch_%s'%(str(self.nFold),str(self.epoch)))\n",
    "        return cv_labels, cv_label_prob\n",
    "    \n",
    "    def accuracy(self, y, y_hat):\n",
    "        return np.mean(np.equal(y_hat, y))\n",
    "    \n",
    "#     def test(self, tstGraph, testBatch, sess):\n",
    "#         # METHOD 2: TO get weights is form of Tensors\n",
    "#         a = saver.restore(sess, os.path.join(checkpoint_path, \"model.ckpt\"))\n",
    "#         trainableVars = tf.get_collection(ops.GraphKeys.TRAINABLE_VARIABLES)\n",
    "#         testDict = getFineTunedEmbeddings([96,96,3], moduleWeightDict, trainableVars, sess)\n",
    "#         embeddings = sess.run([tstGraph['output']], feed_dict={'inpTensor':testBatch})\n",
    "#         return embeddings\n",
    "\n",
    "    def run(self):\n",
    "        # GET THE BATCH DATA FROM THE DISK\n",
    "        dataX, dataY, labelDict = DataFormatter.getPickleFile(\n",
    "            folderPath=path_dict['batchFolderPath'], picklefileName=which_file, getStats=True\n",
    "        )\n",
    "        trnBatch_idx = [list(np.setdiff1d(np.arange(len(dataX)), np.array(i))) for i in  np.arange(len(dataX))]\n",
    "        cvBatch_idx = [i for i in  np.arange(len(dataX))]\n",
    "        logging.info('dataX.shape = %s, dataY.shape = %s',str(dataX.shape), str(dataY.shape))\n",
    "\n",
    "        # Reset graph to do a fresh start\n",
    "        reset_graph()\n",
    "        trn_embed_graph = trainEmbeddings(moduleWeightDict,init_wght_type='random')\n",
    "        self.preprocessGraphDict = Preprocessing().preprocessImageGraph(\n",
    "                                                            imageShape=self.myNet[\"image_shape\"])\n",
    "        # add ops to save and restore model\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            checkpoints = [ck for ck in os.listdir(path_dict['checkpoint_path']) if ck!='.DS_Store']\n",
    "            if len(checkpoints) > 0 and self.myNet['use_checkpoint']:\n",
    "                saver.restore(sess, os.path.join(path_dict['checkpoint_path'], \n",
    "                                                 \"distinct_stratified_model.ckpt\"))\n",
    "\n",
    "            # LOOP FOR N-FOLD CROSS VALIDATION\n",
    "            for nFold, (trn_batch_idx, cv_batch_idx) in enumerate(zip(trnBatch_idx, cvBatch_idx)):\n",
    "                self.nFold = nFold + 1\n",
    "                logging.info('RUNNING : %s FOLD ...........................', str(self.nFold))\n",
    "                trnX = dataX[trn_batch_idx,:]\n",
    "                trnY = dataY[trn_batch_idx,:]\n",
    "                cvX = dataX[cv_batch_idx,:]\n",
    "                cvY = dataY[cv_batch_idx,:]\n",
    "                logging.info('trnX.shape = %s, trnY.shape = %s, cvX.shape = %s, cvY.shape = %s', \n",
    "                      str(trnX.shape), str(trnY.shape), str(cvX.shape), str(cvY.shape))\n",
    "\n",
    "                for epoch in np.arange(10):\n",
    "                    self.epoch = epoch + 1\n",
    "                    logging.info('RUNNING : %s EPOCH ........................', str(self.epoch))\n",
    "                    # Below loop will minimize the triplet loss and update the parameters\n",
    "                    for batchNum, batchX in enumerate(trnX[0:len(trnX),:]):\n",
    "                        logging.info('RUNNING BATCH %s for shape = %s', str(batchNum + 1), str(batchX.shape))\n",
    "                        \n",
    "                        # Step1 : Preprocess the Data\n",
    "                        preprocessedData = self.runPreprocessor(dataIN=batchX, sess=sess)\n",
    "                            \n",
    "                        # Since we improve on our previous prediction, there can be cases where the network has learned a good enough\n",
    "                        # decision boundary (for a batch) and is unable to find hard negative for the triplet selection. In such a case\n",
    "                        # the network would return an empty array, which would raise a run time exception during the graph is computed.\n",
    "                        # For such cases we would except an exception, and let the graph proceed. \n",
    "                        try:\n",
    "                            opt, batch_loss = sess.run([trn_embed_graph['optimizer'], \n",
    "                                                        trn_embed_graph['loss']], \n",
    "                                                        feed_dict={trn_embed_graph['inpTensor']:preprocessedData})\n",
    "                        except Exception:\n",
    "                            logging.info('Exception Raised! Check the log file and confirm if the exception is becasue of empty triplet array. If not then debugg it :)')       \n",
    "                            logging.info(\"Fold = %s, Epoch = %s, Loss = %s\", \n",
    "                                         str(self.nFold), str(self.epoch), \"{:.6f}\".format(batch_loss))\n",
    "                            \n",
    "                        print(\"Fold: \" + str(self.nFold) + \n",
    "                              \", Epoch= \" + str(self.epoch) + \n",
    "                              \", Loss= \" + \"{:.6f}\".format(batch_loss))\n",
    "                    \n",
    "                    save_path = saver.save(sess, os.path.join(path_dict['checkpoint_path'], \"distinct_stratified_model.ckpt\"))\n",
    "\n",
    "                    # Now that we have updated our parameters (weights and biases), we would\n",
    "                    # fetch the embeddings using the updated parameter and train-test model\n",
    "                    # to get an accuracy. Accuracy per epoch is now a good way to go\n",
    "                    self.setNewWeights(sess) # replace the last layer's inception weights with leared finetuned weights\n",
    "                    \n",
    "                    # TRAIN, GET TRAINING PREDICTION AND ACCURACY\n",
    "                    trnX_ = trnX.reshape(-1, trnX.shape[2], trnX.shape[3], trnX.shape[4]) # accumulate all batches\n",
    "                    trnY_ = trnY.flatten()\n",
    "                    train_labels, _ = self.train(trnX_, trnY_, sess)\n",
    "                    tr_acc = self.accuracy(y=trnY_, y_hat=train_labels)\n",
    "                    print (tr_acc)\n",
    "                    \n",
    "                    # GET CROSS VALIDATION PREDICTION AND ACCURACY\n",
    "                    cv_labels, _ = self.cvalid(cvX, sess)\n",
    "                    cv_acc = self.accuracy(y=cvY, y_hat=cv_labels)\n",
    "                    print (cv_acc)\n",
    "                break\n",
    "\n",
    "\n",
    "objExec = Execute(params=moduleWeightDict, myNet=myNet, embeddingType='finetune')\n",
    "objExec.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGH\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "tfdata = tf.cast(np.random.rand(1,1,3,5) + 10, dtype=tf.float32)\n",
    "print (tfdata.get_shape().as_list())\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batchMean, batchVar = tf.nn.moments(tfdata, axes=[0,1,2], name=\"moments\")\n",
    "    print (tfdata.eval())\n",
    "    print (batchMean.eval())\n",
    "    print (batchMean.get_shape().as_list())\n",
    "    print (batchVar.eval())\n",
    "    print (batchVar.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3,4])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'InvalidArgumentError' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Index out of range using input dim 1; input has only 1 dims\n\t [[Node: strided_slice = StridedSlice[Index=DT_INT32, T=DT_INT64, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](PyFunc, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-810e2789272e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Index out of range using input dim 1; input has only 1 dims\n\t [[Node: strided_slice = StridedSlice[Index=DT_INT32, T=DT_INT64, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](PyFunc, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)]]\n\nCaused by op 'strided_slice', defined at:\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-810e2789272e>\", line 8, in <module>\n    y_1 = tf.add(y[:,0], 1)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 538, in _SliceHelper\n    name=name)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 706, in strided_slice\n    shrink_axis_mask=shrink_axis_mask)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5430, in strided_slice\n    name=name)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Index out of range using input dim 1; input has only 1 dims\n\t [[Node: strided_slice = StridedSlice[Index=DT_INT32, T=DT_INT64, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](PyFunc, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-810e2789272e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'dasdsdsdsdsdsdsds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'InvalidArgumentError' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "reset_graph()\n",
    "def my_func(x):\n",
    "    return [x]\n",
    "\n",
    "inp = tf.placeholder(tf.int64)\n",
    "y = tf.py_func(my_func, [inp], tf.int64)\n",
    "y_1 = tf.add(y[:,0], 1)\n",
    "# print (len(y))#.get_shape())\n",
    "\n",
    "# a = np.array([[1,2,3],[4,5,6],[6,7,8]])\n",
    "a = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    try:\n",
    "        yy = sess.run([y_1],feed_dict={inp:a})\n",
    "        print (yy)\n",
    "    except InvalidArgumentError:\n",
    "        print ('dasdsdsdsdsdsdsds')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
