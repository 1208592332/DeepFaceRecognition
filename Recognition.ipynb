{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from data_transformer.data_formatter import DataFormatter\n",
    "from data_transformer.preprocess import Preprocessing\n",
    "\n",
    "from data_transformer.data_prep import DataIO, genDistinctStratifiedBatches, genRandomStratifiedBatches\n",
    "from nn.load_params import layer_name, convShape, getWeights\n",
    "from nn.utils import getTriplets, tripletLoss\n",
    "from train_test.model import *\n",
    "from config import path_dict\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logfile.log\", filemode=\"w\",\n",
    "                    format=\"%(asctime)-15s %(levelname)-8s %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE TIME RUN: \n",
    "------------\n",
    "#### INPUT :  Folder path with images of several people, ensure the image folders are named with the person name\n",
    "#### OUTPUT: Dumps a pickle file with three keys, dataX, dataY, labelDict. \n",
    "            * dataX: images converted into nd array\n",
    "            * dataY: for each record of nd array, Labels are numerical (1,2,3,4,5)\n",
    "            * labelDict: Contains the label corresponding to person name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training = True\n",
    "# verification = True\n",
    "\n",
    "# if training:\n",
    "#     objDP = DataFormatter(path_dict['parent_path'], 'training')\n",
    "#     objDP.createResizedData()\n",
    "#     dataX, dataY, labelDict = objDP.imageToArray()\n",
    "#     DataFormatter.dumpPickleFile(dataX, dataY, labelDict,\n",
    "#                                folderPath=os.path.join(path_dict['data_model_path']),\n",
    "#                                picklefileName='training_imgarr.pickle')\n",
    "# if verification:\n",
    "#     objDP = DataFormatter(path_dict['parent_path'], 'verification')\n",
    "#     objDP.createResizedData()\n",
    "#     dataX, dataY, labelDict = objDP.imageToArray()\n",
    "#     DataFormatter.dumpPickleFile(dataX, dataY, labelDict,\n",
    "#                                folderPath=os.path.join(path_dict['data_model_path']),\n",
    "#                                picklefileName='verification_imgarr.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE RANDOM BATCHES:\n",
    "----------------\n",
    "#### INPUT: Image nd array as input  [num_images, imgX, imgY, num_channels]\n",
    "#### OUTPUT: Outputs a pickle file with shape [num_batches, num_image_per_batch, imgX, imgY, num_channels]\n",
    "\n",
    "       *  We would wanna do stocastic descent for minibatches and update the parameters perbatch. This module attempts to create stratified batches (each batch would have equal distribution of labels). \n",
    "       \n",
    "       * when genDistinctStratifiedBatches. The images in the batched would be distinct (would not repeat)\n",
    "       * when genRandomStratifiedBatches. No seed is set for shuffling. So Images in different batches may repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# debugg = True\n",
    "# numImgsPerLabels = 60 # num image per label per batch\n",
    "# numBatches = 10\n",
    "# if debugg:\n",
    "#     trainX, trainY, trainLabelDict = DataIO.getPickleFile(path_dict['data_model_path'],\n",
    "#                                                                  'training_imgarr.pickle')\n",
    "#     verX, verY, verLabelDict = DataIO.getPickleFile(path_dict['data_model_path'],\n",
    "#                                                            'verification_imgarr.pickle')\n",
    "#     print(trainX.shape, trainY.shape)\n",
    "#     print(verX.shape, verY.shape)\n",
    "#     genDistinctStratifiedBatches(trainX, trainY, numImgsPerLabels=numImgsPerLabels, numBatches=numBatches,\n",
    "#                           fileName='distinct_stratified_batches.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## RESET TENSORFLOW GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET INCEPTION WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "moduleWeightDict = getWeights(path_dict['inception_nn4small_weights_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO's:\n",
    "\n",
    "1. Remove the random weight initialiazer for the last layer, and initialize it \n",
    "   with the inception net weights.  **DONE**\n",
    "\n",
    "2. implement a module to save weights as checkpoints to the disk.  **DONE**\n",
    "\n",
    "3. create a function to toggle between Random weight initializer, Inception net weight initializer \n",
    "   and using the saved checkpoint for the last Inception layer. **DONE**\n",
    "   \n",
    "4.0 : REMEBER TO STORE THE exponential weighted average of mean and variable in the batch normalization \n",
    "      fine tune function. SET THESE AS A VARIABLE (LOOK AT CIFAR CODE FOR HELP)\n",
    " \n",
    "4. Add more images. **DONE**\n",
    "\n",
    "5. Create a complete workflow train the network and perform cross validation: **DONE**\n",
    "\n",
    "6. Store 1 image encodings for the 3-4 labels you have.\n",
    "\n",
    "7. For a new image, pass the image throught network, get the encoding and see which is the most closest face using the encoding from the step 6.\n",
    "\n",
    "8. Try :\n",
    "    1. SVM classfication on embedding feature space: Get cross validation accuracy: **DONE**\n",
    "    2. Softmax classification on embedding feature space: Get cross validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class SVM():\n",
    "    '''\n",
    "    # The embeddings in a nutshell are features. The face image goes through a complex network and results in\n",
    "    # embeddings that captures complex features of a face. SVM's are good at classifying small datasets.\n",
    "    # SVM are also robust to over fitting. The idea here is that we would wanna learn a SVM classifier using the\n",
    "    # embeddings as the feature space and see for the given embedding, how many times we are able to predict the\n",
    "    # correct class\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, embeddings, labels, model_name=None):\n",
    "        '''\n",
    "        :param embeddings:   Embeddings of the image\n",
    "        :param labels:       labels\n",
    "        :return:\n",
    "        '''\n",
    "        model = SVC(kernel='linear', probability=True)\n",
    "        model.fit(embeddings, labels)\n",
    "        joblib.dump(model, os.path.join(path_dict['classification_model_path'], str(model_name)+\"_svm.sav\"))\n",
    "        \n",
    "    def classify(self, embeddings, model_name=None):\n",
    "        '''\n",
    "        :param embeddings: Image embeddings to classify\n",
    "        :param model_name:\n",
    "        :return:\n",
    "        '''\n",
    "        model = joblib.load(os.path.join(path_dict['classification_model_path'], str(model_name)+\"_svm.sav\"))\n",
    "        predLabels = model.predict_proba(embeddings)\n",
    "        top_label_idx = np.argmax(predLabels, axis=1)\n",
    "        labelProb = predLabels[np.arange(len(top_label_idx)), top_label_idx]\n",
    "        return top_label_idx, labelProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input data (X) is:  (10, 18, 96, 96, 3)\n",
      "The shape of input data (Y) is:  (10, 18)\n",
      "Unique labels in dataY is:  [ 0.  1.  2.]\n",
      "Label dict:  None\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'imageShape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-aa99ec0c226c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0mobjExec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmoduleWeightDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyNet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddingType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'finetune'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m \u001b[0mobjExec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-aa99ec0c226c>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# Reset graph to do a fresh start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mreset_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mtrn_embed_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoduleWeightDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit_wght_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'random'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         self.preprocessGraphDict = Preprocessing().preprocessImageGraph(\n\u001b[1;32m     96\u001b[0m                                                             imageShape=self.myNet[\"image_shape\"])\n",
      "\u001b[0;32m~/All-Program/App/DeepFaceRecognition/train_test/model.py\u001b[0m in \u001b[0;36mtrainEmbeddings\u001b[0;34m(weightDict, init_wght_type)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     embeddingDict = trainModel_FT(myNet['imageShape'], params=weightDict,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                   init_wght_type=init_wght_type)\n\u001b[1;32m     61\u001b[0m     \u001b[0membeddingDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddingDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'imageShape'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from config import myNet\n",
    "\n",
    "which_file = 'distinct_stratified_batches.pickle'\n",
    "checkpoint_file_name = 'distinct_stratified_model'\n",
    "\n",
    "\n",
    "'''\n",
    "dataX = [num_batches, image_per_batch, image_x, image_y, image_channels]\n",
    "dataY = [num_batches, labels]\n",
    "\n",
    "'''\n",
    "\n",
    "class Execute():\n",
    "    def __init__(self, params, myNet, embeddingType='finetune'):\n",
    "        self.params = params\n",
    "        self.embeddingType = embeddingType\n",
    "        self.myNet = myNet\n",
    "        \n",
    "    def runPreprocessor(self, dataIN, sess):\n",
    "        preprocessedData = np.ndarray(shape=(dataIN.shape), dtype='float32')\n",
    "        for numImage in np.arange(dataIN.shape[0]):\n",
    "            feed_dict = {\n",
    "                self.preprocessGraphDict['imageIN']:dataIN[numImage,:]\n",
    "            }\n",
    "            preprocessedData[numImage,:] = sess.run(self.preprocessGraphDict['imageOUT'],\n",
    "                                                      feed_dict=feed_dict)\n",
    "        return preprocessedData\n",
    "        \n",
    "    def setNewWeights(self, sess):\n",
    "        trainableVars = tf.get_collection(ops.GraphKeys.TRAINABLE_VARIABLES)\n",
    "        if self.embeddingType=='finetune':\n",
    "            for var in trainableVars:\n",
    "                scope, name = var.name.split(':')[0].split('/')\n",
    "                if len(self.params[scope][name]) != 0:\n",
    "                    var_ = sess.run(var)\n",
    "                    logging.info('Updating param with scope %s and name %s and shape %s with shape %s',\n",
    "                                 str(scope), str(name), str(self.params[scope][name].shape), str(var_.shape))\n",
    "                    self.params[scope][name] = var_\n",
    "                else:\n",
    "                    raise ValueError('It seems that the scope %s or variable %s didnt exist in the dictionary ' % (str(scope), str(name)))\n",
    "    \n",
    "    def train(self, trnX_, trnY_, sess):\n",
    "        '''\n",
    "            1. Make the use of getEmbedding to get the graph with last layer parameter updated with the \n",
    "            fine tuned weights.\n",
    "            2. Get the new embedding for batch/epoch using the computation graph\n",
    "            3. Use the embeddings as feature for a classifier (svm/softmax)\n",
    "            4. Classify faces using the new embeddings.\n",
    "        '''\n",
    "        trainEmbedGraph = getEmbeddings([96,96,3], self.params)\n",
    "        embeddings = sess.run(trainEmbedGraph['output'], \n",
    "                              feed_dict={trainEmbedGraph['inpTensor']:trnX_})\n",
    "        logging.info('Training Embeddings shape %s', embeddings.shape)\n",
    "        obj_svm = SVM()\n",
    "        obj_svm.train(embeddings, labels=trnY_, \n",
    "                      model_name='nFold_%s_batch_%s'%(str(self.nFold),str(self.epoch)))\n",
    "        train_labels, train_label_prob = obj_svm.classify(embeddings, \n",
    "                                             model_name='nFold_%s_batch_%s'%(str(self.nFold),str(self.epoch)))\n",
    "        return train_labels, train_label_prob\n",
    "    \n",
    "    def cvalid(self, cvX_, sess):\n",
    "        embedGraph = getEmbeddings(myNet['image_shape'], self.params)\n",
    "        embeddings = sess.run(embedGraph['output'], \n",
    "                              feed_dict={embedGraph['inpTensor']:cvX_})\n",
    "        logging.info('Cross validation Embeddings shape %s', embeddings.shape)\n",
    "        obj_svm = SVM()\n",
    "        cv_labels, cv_label_prob = obj_svm.classify(embeddings, \n",
    "                                             model_name='nFold_%s_batch_%s'%(str(self.nFold),str(self.epoch)))\n",
    "        return cv_labels, cv_label_prob\n",
    "    \n",
    "    def accuracy(self, y, y_hat):\n",
    "        return np.mean(np.equal(y_hat, y))\n",
    "    \n",
    "#     def test(self, tstGraph, testBatch, sess):\n",
    "#         # METHOD 2: TO get weights is form of Tensors\n",
    "#         a = saver.restore(sess, os.path.join(checkpoint_path, \"model.ckpt\"))\n",
    "#         trainableVars = tf.get_collection(ops.GraphKeys.TRAINABLE_VARIABLES)\n",
    "#         testDict = getFineTunedEmbeddings([96,96,3], moduleWeightDict, trainableVars, sess)\n",
    "#         embeddings = sess.run([tstGraph['output']], feed_dict={'inpTensor':testBatch})\n",
    "#         return embeddings\n",
    "\n",
    "    def run(self):\n",
    "        # GET THE BATCH DATA FROM THE DISK\n",
    "        dataX, dataY, labelDict = DataFormatter.getPickleFile(\n",
    "            folderPath=path_dict['batchFolderPath'], picklefileName=which_file, getStats=True\n",
    "        )\n",
    "        trnBatch_idx = [list(np.setdiff1d(np.arange(len(dataX)), np.array(i))) for i in  np.arange(len(dataX))]\n",
    "        cvBatch_idx = [i for i in  np.arange(len(dataX))]\n",
    "        logging.info('dataX.shape = %s, dataY.shape = %s',str(dataX.shape), str(dataY.shape))\n",
    "\n",
    "        # Reset graph to do a fresh start\n",
    "        reset_graph()\n",
    "        trn_embed_graph = trainEmbeddings(moduleWeightDict,init_wght_type='random')\n",
    "        self.preprocessGraphDict = Preprocessing().preprocessImageGraph(\n",
    "                                                            imageShape=self.myNet[\"image_shape\"])\n",
    "        # add ops to save and restore model\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            checkpoints = [ck for ck in os.listdir(path_dict['checkpoint_path']) if ck!='.DS_Store']\n",
    "            if len(checkpoints) > 0 and self.myNet['use_checkpoint']:\n",
    "                saver.restore(sess, os.path.join(path_dict['checkpoint_path'], \n",
    "                                                 \"distinct_stratified_model.ckpt\"))\n",
    "\n",
    "            # LOOP FOR N-FOLD CROSS VALIDATION\n",
    "            for nFold, (trn_batch_idx, cv_batch_idx) in enumerate(zip(trnBatch_idx, cvBatch_idx)):\n",
    "                self.nFold = nFold + 1\n",
    "                logging.info('RUNNING : %s FOLD ...........................', str(self.nFold))\n",
    "                trnX = dataX[trn_batch_idx,:]\n",
    "                trnY = dataY[trn_batch_idx,:]\n",
    "                cvX = dataX[cv_batch_idx,:]\n",
    "                cvY = dataY[cv_batch_idx,:]\n",
    "                logging.info('trnX.shape = %s, trnY.shape = %s, cvX.shape = %s, cvY.shape = %s', \n",
    "                      str(trnX.shape), str(trnY.shape), str(cvX.shape), str(cvY.shape))\n",
    "\n",
    "                for epoch in np.arange(10):\n",
    "                    self.epoch = epoch + 1\n",
    "                    logging.info('RUNNING : %s EPOCH ........................', str(self.epoch))\n",
    "                    # Below loop will minimize the triplet loss and update the parameters\n",
    "                    for batchNum, batchX in enumerate(trnX[0:len(trnX),:]):\n",
    "                        logging.info('RUNNING BATCH shape = %s', str(batchX.shape))\n",
    "                        \n",
    "                        # Step1 : Preprocess the Data\n",
    "                        preprocessedData = self.runPreprocessor(dataIN=batchX, sess=sess)\n",
    "                    \n",
    "                        opt, batch_loss = sess.run([trn_embed_graph['optimizer'], \n",
    "                                                    trn_embed_graph['loss']], \n",
    "                                                    feed_dict={trn_embed_graph['inpTensor']:preprocessedData})\n",
    "                    print(\"Fold: \" + str(self.nFold) + \n",
    "                          \", Epoch= \" + str(self.epoch) + \n",
    "                          \", Loss= \" + \"{:.6f}\".format(batch_loss))\n",
    "                    save_path = saver.save(sess, os.path.join(path_dict['checkpoint_path'], \"distinct_stratified_model.ckpt\"))\n",
    "\n",
    "                    # Now that we have updated our parameters (weights and biases), we would\n",
    "                    # fetch the embeddings using the updated parameter and train-test model\n",
    "                    # to get an accuracy. Accuracy per epoch is now a good way to go\n",
    "                    self.setNewWeights(sess) # replace the last layer's inception weights with leared finetuned weights\n",
    "                    \n",
    "                    # TRAIN, GET TRAINING PREDICTION AND ACCURACY\n",
    "                    trnX_ = trnX.reshape(-1, trnX.shape[2], trnX.shape[3], trnX.shape[4]) # accumulate all batches\n",
    "                    trnY_ = trnY.flatten()\n",
    "                    train_labels, _ = self.train(trnX_, trnY_, sess)\n",
    "                    tr_acc = self.accuracy(y=trnY_, y_hat=train_labels)\n",
    "                    print (tr_acc)\n",
    "                    \n",
    "                    # GET CROSS VALIDATION PREDICTION AND ACCURACY\n",
    "                    cv_labels, _ = self.cvalid(cvX, sess)\n",
    "                    cv_acc = self.accuracy(y=cvY, y_hat=cv_labels)\n",
    "                    print (cv_acc)\n",
    "                break\n",
    "\n",
    "\n",
    "objExec = Execute(params=moduleWeightDict, myNet=myNet, embeddingType='finetune')\n",
    "objExec.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGH\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "tfdata = tf.cast(np.random.rand(1,1,3,5) + 10, dtype=tf.float32)\n",
    "print (tfdata.get_shape().as_list())\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batchMean, batchVar = tf.nn.moments(tfdata, axes=[0,1,2], name=\"moments\")\n",
    "    print (tfdata.eval())\n",
    "    print (batchMean.eval())\n",
    "    print (batchMean.get_shape().as_list())\n",
    "    print (batchVar.eval())\n",
    "    print (batchVar.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3,4])[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
