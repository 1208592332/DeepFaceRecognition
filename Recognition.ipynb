{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from data_transformer.data_formatter import DataFormatter\n",
    "from data_transformer.preprocess import Preprocessing\n",
    "\n",
    "from data_transformer.data_prep import DataIO, genDistinctStratifiedBatches, genRandomStratifiedBatches\n",
    "from nn.load_params import layer_name, convShape, getWeights\n",
    "from nn.utils import getTriplets, tripletLoss\n",
    "from train_test.model import *\n",
    "from config import path_dict\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logfile.log\", filemode=\"w\",\n",
    "                    format=\"%(asctime)-15s %(levelname)-8s %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE TIME RUN: \n",
    "------------\n",
    "#### INPUT :  Folder path with images of several people, ensure the image folders are named with the person name\n",
    "#### OUTPUT: Dumps a pickle file with three keys, dataX, dataY, labelDict. \n",
    "            * dataX: images converted into nd array\n",
    "            * dataY: for each record of nd array, Labels are numerical (1,2,3,4,5)\n",
    "            * labelDict: Contains the label corresponding to person name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training = True\n",
    "# verification = True\n",
    "\n",
    "# if training:\n",
    "#     objDP = DataFormatter(path_dict['parent_path'], 'training')\n",
    "#     objDP.createResizedData()\n",
    "#     dataX, dataY, labelDict = objDP.imageToArray()\n",
    "#     DataFormatter.dumpPickleFile(dataX, dataY, labelDict,\n",
    "#                                folderPath=os.path.join(path_dict['data_model_path']),\n",
    "#                                picklefileName='training_imgarr.pickle')\n",
    "# if verification:\n",
    "#     objDP = DataFormatter(path_dict['parent_path'], 'verification')\n",
    "#     objDP.createResizedData()\n",
    "#     dataX, dataY, labelDict = objDP.imageToArray()\n",
    "#     DataFormatter.dumpPickleFile(dataX, dataY, labelDict,\n",
    "#                                folderPath=os.path.join(path_dict['data_model_path']),\n",
    "#                                picklefileName='verification_imgarr.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE RANDOM BATCHES:\n",
    "----------------\n",
    "#### INPUT: Image nd array as input  [num_images, imgX, imgY, num_channels]\n",
    "#### OUTPUT: Outputs a pickle file with shape [num_batches, num_image_per_batch, imgX, imgY, num_channels]\n",
    "\n",
    "       *  We would wanna do stocastic descent for minibatches and update the parameters perbatch. This module attempts to create stratified batches (each batch would have equal distribution of labels). \n",
    "       \n",
    "       * when genDistinctStratifiedBatches. The images in the batched would be distinct (would not repeat)\n",
    "       * when genRandomStratifiedBatches. No seed is set for shuffling. So Images in different batches may repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# debugg = True\n",
    "# numImgsPerLabels = 60 # num image per label per batch\n",
    "# numBatches = 10\n",
    "# if debugg:\n",
    "#     trainX, trainY, trainLabelDict = DataIO.getPickleFile(path_dict['data_model_path'],\n",
    "#                                                                  'training_imgarr.pickle')\n",
    "#     verX, verY, verLabelDict = DataIO.getPickleFile(path_dict['data_model_path'],\n",
    "#                                                            'verification_imgarr.pickle')\n",
    "#     print(trainX.shape, trainY.shape)\n",
    "#     print(verX.shape, verY.shape)\n",
    "#     genDistinctStratifiedBatches(trainX, trainY, numImgsPerLabels=numImgsPerLabels, numBatches=numBatches,\n",
    "#                           fileName='distinct_stratified_batches.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## RESET TENSORFLOW GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET INCEPTION WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "moduleWeightDict = getWeights(path_dict['inception_nn4small_weights_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO's:\n",
    "\n",
    "1. Remove the random weight initialiazer for the last layer, and initialize it \n",
    "   with the inception net weights.  **DONE**\n",
    "\n",
    "2. implement a module to save weights as checkpoints to the disk.  **DONE**\n",
    "\n",
    "3. create a function to toggle between Random weight initializer, Inception net weight initializer \n",
    "   and using the saved checkpoint for the last Inception layer. **DONE**\n",
    "   \n",
    "4 : REMEBER TO STORE THE exponential weighted average of mean and variable in the batch normalization \n",
    "      fine tune function. SET THESE AS A VARIABLE (LOOK AT CIFAR CODE FOR HELP) **DONE**\n",
    " \n",
    "5. Add more images.\n",
    "\n",
    "6. Create a complete workflow train the network and perform cross validation: **DONE**\n",
    "\n",
    "7. Store 1 image encodings for the 3-4 labels you have.\n",
    "\n",
    "8. For a new image, pass the image throught network, get the encoding and see which is the most closest face using the encoding from the step 6.\n",
    "\n",
    "9. Try :\n",
    "    1. SVM classfication on embedding feature space: Get cross validation accuracy: **DONE**\n",
    "    2. Softmax classification on embedding feature space: Get cross validation accuracy. \n",
    "    \n",
    "10. The triplet selection now has, random selection of Hard negative. Having random selection makes it difficult to adjust parameters. So make is generated by a sedd, but the sees itself should be generated randomly via a different sees. Since having the same seeed decide a triplet would be problematic becasue the same hard negative would always be selected. **DONE**\n",
    "\n",
    "11. Add learning rate decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class SVM():\n",
    "    '''\n",
    "    # The embeddings in a nutshell are features. The face image goes through a complex network and results in\n",
    "    # embeddings that captures complex features of a face. SVM's are good at classifying small datasets.\n",
    "    # SVM are also robust to over fitting. The idea here is that we would wanna learn a SVM classifier using the\n",
    "    # embeddings as the feature space and see for the given embedding, how many times we are able to predict the\n",
    "    # correct class\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, embeddings, labels, model_name=None):\n",
    "        '''\n",
    "        :param embeddings:   Embeddings of the image\n",
    "        :param labels:       labels\n",
    "        :return:\n",
    "        '''\n",
    "        model = SVC(kernel='linear', probability=True)\n",
    "        model.fit(embeddings, labels)\n",
    "        joblib.dump(model, os.path.join(path_dict['classification_model_path'], str(model_name)+\"_svm.sav\"))\n",
    "        \n",
    "    def classify(self, embeddings, model_name=None):\n",
    "        '''\n",
    "        :param embeddings: Image embeddings to classify\n",
    "        :param model_name:\n",
    "        :return:\n",
    "        '''\n",
    "        model = joblib.load(os.path.join(path_dict['classification_model_path'], str(model_name)+\"_svm.sav\"))\n",
    "        predLabels = model.predict_proba(embeddings)\n",
    "        top_label_idx = np.argmax(predLabels, axis=1)\n",
    "        labelProb = predLabels[np.arange(len(top_label_idx)), top_label_idx]\n",
    "        return top_label_idx, labelProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input data (X) is:  (10, 18, 96, 96, 3)\n",
      "The shape of input data (Y) is:  (10, 18)\n",
      "Unique labels in dataY is:  [ 0.  1.  2.]\n",
      "Label dict:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Epoch= 1, Loss= 7.284033\n",
      "Fold: 1, Epoch= 1, Loss= 9.527963\n",
      "Fold: 1, Epoch= 1, Loss= 9.313075\n",
      "Fold: 1, Epoch= 1, Loss= 7.837997\n",
      "Fold: 1, Epoch= 1, Loss= 6.369949\n",
      "Fold: 1, Epoch= 1, Loss= 7.447740\n",
      "Fold: 1, Epoch= 1, Loss= 8.133675\n",
      "Fold: 1, Epoch= 1, Loss= 7.821722\n",
      "Fold: 1, Epoch= 1, Loss= 8.635121\n",
      "0.104938271605\n",
      "0.166666666667\n",
      "Fold: 1, Epoch= 2, Loss= 5.480565\n",
      "Fold: 1, Epoch= 2, Loss= 8.390961\n",
      "Fold: 1, Epoch= 2, Loss= 8.070734\n",
      "Fold: 1, Epoch= 2, Loss= 7.137790\n",
      "Fold: 1, Epoch= 2, Loss= 6.987082\n",
      "Fold: 1, Epoch= 2, Loss= 7.740933\n",
      "Fold: 1, Epoch= 2, Loss= 7.474596\n",
      "Fold: 1, Epoch= 2, Loss= 7.814251\n",
      "Fold: 1, Epoch= 2, Loss= 7.094688\n",
      "0.611111111111\n",
      "0.666666666667\n",
      "Fold: 1, Epoch= 3, Loss= 2.010153\n",
      "Fold: 1, Epoch= 3, Loss= 7.072509\n",
      "Fold: 1, Epoch= 3, Loss= 5.135334\n",
      "Fold: 1, Epoch= 3, Loss= 5.959037\n",
      "Fold: 1, Epoch= 3, Loss= 5.256696\n",
      "Fold: 1, Epoch= 3, Loss= 4.948030\n",
      "Fold: 1, Epoch= 3, Loss= 6.665016\n",
      "Fold: 1, Epoch= 3, Loss= 5.308676\n",
      "Fold: 1, Epoch= 3, Loss= 5.141862\n",
      "0.333333333333\n",
      "0.388888888889\n",
      "Fold: 1, Epoch= 4, Loss= 1.003949\n",
      "Fold: 1, Epoch= 4, Loss= 6.063673\n",
      "Fold: 1, Epoch= 4, Loss= 5.637844\n",
      "Fold: 1, Epoch= 4, Loss= 5.656313\n",
      "Fold: 1, Epoch= 4, Loss= 3.693146\n",
      "Fold: 1, Epoch= 4, Loss= 4.051355\n",
      "Fold: 1, Epoch= 4, Loss= 5.644923\n",
      "Fold: 1, Epoch= 4, Loss= 3.423684\n",
      "Fold: 1, Epoch= 4, Loss= 3.380942\n",
      "0.0864197530864\n",
      "0.0555555555556\n",
      "Fold: 1, Epoch= 5, Loss= 1.902433\n",
      "Fold: 1, Epoch= 5, Loss= 5.506618\n",
      "Fold: 1, Epoch= 5, Loss= 3.207280\n",
      "Fold: 1, Epoch= 5, Loss= 4.161041\n",
      "Fold: 1, Epoch= 5, Loss= 2.455326\n",
      "Fold: 1, Epoch= 5, Loss= 2.182091\n",
      "Fold: 1, Epoch= 5, Loss= 4.810462\n",
      "Fold: 1, Epoch= 5, Loss= 3.200527\n",
      "Fold: 1, Epoch= 5, Loss= 2.638669\n",
      "0.611111111111\n",
      "0.444444444444\n",
      "Fold: 1, Epoch= 6, Loss= 0.395116\n",
      "Fold: 1, Epoch= 6, Loss= 3.249562\n",
      "Fold: 1, Epoch= 6, Loss= 4.201564\n",
      "Fold: 1, Epoch= 6, Loss= 1.378172\n",
      "Fold: 1, Epoch= 6, Loss= 2.467503\n",
      "Fold: 1, Epoch= 6, Loss= 0.589100\n",
      "Fold: 1, Epoch= 6, Loss= 2.500074\n",
      "Fold: 1, Epoch= 6, Loss= 2.806240\n",
      "Fold: 1, Epoch= 6, Loss= 0.844519\n",
      "0.283950617284\n",
      "0.388888888889\n",
      "Fold: 1, Epoch= 7, Loss= 0.620864\n",
      "Fold: 1, Epoch= 7, Loss= 0.991968\n",
      "Fold: 1, Epoch= 7, Loss= 0.601912\n",
      "Fold: 1, Epoch= 7, Loss= 3.346652\n",
      "Fold: 1, Epoch= 7, Loss= 1.560082\n",
      "Fold: 1, Epoch= 7, Loss= 2.177385\n",
      "Fold: 1, Epoch= 7, Loss= 2.573829\n",
      "Fold: 1, Epoch= 7, Loss= 2.823148\n",
      "Fold: 1, Epoch= 7, Loss= 0.619728\n",
      "0.70987654321\n",
      "0.5\n",
      "Fold: 1, Epoch= 8, Loss= 0.192969\n",
      "Fold: 1, Epoch= 8, Loss= 0.601584\n",
      "Fold: 1, Epoch= 8, Loss= 2.078254\n",
      "Fold: 1, Epoch= 8, Loss= 0.199585\n",
      "Fold: 1, Epoch= 8, Loss= 0.383460\n",
      "Fold: 1, Epoch= 8, Loss= 1.419144\n",
      "Fold: 1, Epoch= 8, Loss= 3.641653\n",
      "Fold: 1, Epoch= 8, Loss= 0.598914\n",
      "Fold: 1, Epoch= 8, Loss= 1.392277\n",
      "0.728395061728\n",
      "0.555555555556\n",
      "Fold: 1, Epoch= 9, Loss= 0.781791\n",
      "Fold: 1, Epoch= 9, Loss= 1.789986\n",
      "Fold: 1, Epoch= 9, Loss= 0.581512\n",
      "Fold: 1, Epoch= 9, Loss= 1.373905\n",
      "Fold: 1, Epoch= 9, Loss= 1.373905\n",
      "Fold: 1, Epoch= 9, Loss= 0.976823\n",
      "Fold: 1, Epoch= 9, Loss= 1.240072\n",
      "Fold: 1, Epoch= 9, Loss= 0.778050\n",
      "Fold: 1, Epoch= 9, Loss= 0.382404\n",
      "0.240740740741\n",
      "0.333333333333\n",
      "Fold: 1, Epoch= 10, Loss= 0.192249\n",
      "Fold: 1, Epoch= 10, Loss= 0.385164\n",
      "Fold: 1, Epoch= 10, Loss= 0.190461\n",
      "Fold: 1, Epoch= 10, Loss= 0.190461\n",
      "Fold: 1, Epoch= 10, Loss= 0.391642\n",
      "Fold: 1, Epoch= 10, Loss= 0.805552\n",
      "Fold: 1, Epoch= 10, Loss= 0.411559\n",
      "Fold: 1, Epoch= 10, Loss= 0.382943\n",
      "Fold: 1, Epoch= 10, Loss= 0.816299\n",
      "0.70987654321\n",
      "0.611111111111\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "import config\n",
    "from config import myNet\n",
    "\n",
    "which_file = 'distinct_stratified_batches.pickle'\n",
    "checkpoint_file_name = 'distinct_stratified_model'\n",
    "\n",
    "\n",
    "'''\n",
    "dataX = [num_batches, image_per_batch, image_x, image_y, image_channels]\n",
    "dataY = [num_batches, labels]\n",
    "\n",
    "'''\n",
    "\n",
    "class Execute():\n",
    "    def __init__(self, params, myNet, embeddingType='finetune'):\n",
    "        self.params = params\n",
    "        self.embeddingType = embeddingType\n",
    "        self.myNet = myNet\n",
    "        self.myNet['learning_rate'] = 0.0001\n",
    "        \n",
    "    def runPreprocessor(self, dataIN, sess):\n",
    "        preprocessedData = np.ndarray(shape=(dataIN.shape), dtype='float32')\n",
    "        for numImage in np.arange(dataIN.shape[0]):\n",
    "            feed_dict = {\n",
    "                self.preprocessGraphDict['imageIN']:dataIN[numImage,:]\n",
    "            }\n",
    "            preprocessedData[numImage,:] = sess.run(self.preprocessGraphDict['imageOUT'],\n",
    "                                                      feed_dict=feed_dict)\n",
    "        return preprocessedData\n",
    "        \n",
    "    def setNewWeights(self, sess):\n",
    "        logging.info('UPDATING WEITHGS WITH FINETUNED WEIGHTS .........')\n",
    "#         trainableVars = tf.get_collection(ops.GraphKeys.TRAINABLE_VARIABLES)\n",
    "        if self.embeddingType=='finetune':\n",
    "            for learned_vars in config.finetune_variables:\n",
    "                scope, name = learned_vars.split(':')[0].split('/')\n",
    "                if len(self.params[scope][name]) != 0:\n",
    "                    var_ = sess.run(learned_vars)\n",
    "                    logging.info('Updating param with scope %s and name %s and shape %s with shape %s',\n",
    "                                 str(scope), str(name), str(self.params[scope][name].shape), str(var_.shape))\n",
    "                    self.params[scope][name] = var_\n",
    "                else:\n",
    "                    raise ValueError('It seems that the scope %s or variable %s didnt exist in the dictionary ' % (str(scope), str(name)))\n",
    "    \n",
    "    def train(self, trnX_, trnY_, sess):\n",
    "        '''\n",
    "            1. Make the use of getEmbedding to get the graph with last layer parameter updated with the \n",
    "            fine tuned weights.\n",
    "            2. Get the new embedding for batch/epoch using the computation graph\n",
    "            3. Use the embeddings as feature for a classifier (svm/softmax)\n",
    "            4. Classify faces using the new embeddings.\n",
    "        '''\n",
    "        trainEmbedGraph = getEmbeddings(myNet['image_shape'], self.params)\n",
    "        embeddings = sess.run(trainEmbedGraph['output'], \n",
    "                              feed_dict={trainEmbedGraph['inpTensor']:trnX_})\n",
    "        logging.info('Training Embeddings shape %s', embeddings.shape)\n",
    "        obj_svm = SVM()\n",
    "        obj_svm.train(embeddings, labels=trnY_, \n",
    "                      model_name='nFold_%s_batch_%s'%(str(self.nFold),str(self.epoch)))\n",
    "        train_labels, train_label_prob = obj_svm.classify(embeddings, \n",
    "                                             model_name='nFold_%s_batch_%s'%(str(self.nFold),str(self.epoch)))\n",
    "        return train_labels, train_label_prob\n",
    "    \n",
    "    def cvalid(self, cvX_, sess):\n",
    "        embedGraph = getEmbeddings(myNet['image_shape'], self.params)\n",
    "        embeddings = sess.run(embedGraph['output'], \n",
    "                              feed_dict={embedGraph['inpTensor']:cvX_})\n",
    "        logging.info('Cross validation Embeddings shape %s', embeddings.shape)\n",
    "        obj_svm = SVM()\n",
    "        cv_labels, cv_label_prob = obj_svm.classify(embeddings, \n",
    "                                             model_name='nFold_%s_batch_%s'%(str(self.nFold),str(self.epoch)))\n",
    "        return cv_labels, cv_label_prob\n",
    "    \n",
    "    def accuracy(self, y, y_hat):\n",
    "        return np.mean(np.equal(y_hat, y))\n",
    "    \n",
    "#     def test(self, tstGraph, testBatch, sess):\n",
    "#         # METHOD 2: TO get weights is form of Tensors\n",
    "#         a = saver.restore(sess, os.path.join(checkpoint_path, \"model.ckpt\"))\n",
    "#         trainableVars = tf.get_collection(ops.GraphKeys.TRAINABLE_VARIABLES)\n",
    "#         testDict = getFineTunedEmbeddings([96,96,3], moduleWeightDict, trainableVars, sess)\n",
    "#         embeddings = sess.run([tstGraph['output']], feed_dict={'inpTensor':testBatch})\n",
    "#         return embeddings\n",
    "\n",
    "    def run(self):\n",
    "        # GET THE BATCH DATA FROM THE DISK\n",
    "        dataX, dataY, labelDict = DataFormatter.getPickleFile(\n",
    "            folderPath=path_dict['batchFolderPath'], picklefileName=which_file, getStats=True\n",
    "        )\n",
    "        trnBatch_idx = [list(np.setdiff1d(np.arange(len(dataX)), np.array(i))) for i in  np.arange(len(dataX))]\n",
    "        cvBatch_idx = [i for i in  np.arange(len(dataX))]\n",
    "        logging.info('dataX.shape = %s, dataY.shape = %s',str(dataX.shape), str(dataY.shape))\n",
    "\n",
    "        # Reset graph to do a fresh start\n",
    "        reset_graph()\n",
    "        trn_embed_graph = trainEmbeddings(moduleWeightDict,init_wght_type='random')\n",
    "        self.preprocessGraphDict = Preprocessing().preprocessImageGraph(\n",
    "                                                            imageShape=self.myNet[\"image_shape\"])\n",
    "        # add ops to save and restore model\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            checkpoints = [ck for ck in os.listdir(path_dict['checkpoint_path']) if ck!='.DS_Store']\n",
    "            if len(checkpoints) > 0 and self.myNet['use_checkpoint']:\n",
    "                saver.restore(sess, os.path.join(path_dict['checkpoint_path'], \n",
    "                                                 \"distinct_stratified_model.ckpt\"))\n",
    "\n",
    "            # LOOP FOR N-FOLD CROSS VALIDATION\n",
    "            for nFold, (trn_batch_idx, cv_batch_idx) in enumerate(zip(trnBatch_idx, cvBatch_idx)):\n",
    "                self.nFold = nFold + 1\n",
    "                logging.info('RUNNING : %s FOLD ...........................', str(self.nFold))\n",
    "                trnX = dataX[trn_batch_idx,:]\n",
    "                trnY = dataY[trn_batch_idx,:]\n",
    "                cvX = dataX[cv_batch_idx,:]\n",
    "                cvY = dataY[cv_batch_idx,:]\n",
    "                logging.info('trnX.shape = %s, trnY.shape = %s, cvX.shape = %s, cvY.shape = %s', \n",
    "                      str(trnX.shape), str(trnY.shape), str(cvX.shape), str(cvY.shape))\n",
    "\n",
    "                for epoch in np.arange(10):\n",
    "                    self.epoch = epoch + 1\n",
    "                    logging.info('RUNNING : %s EPOCH ........................', str(self.epoch))\n",
    "                    # Below loop will minimize the triplet loss and update the parameters\n",
    "                    for batchNum, batchX in enumerate(trnX[0:len(trnX),:]):\n",
    "                        logging.info('RUNNING BATCH %s for shape = %s', str(batchNum + 1), str(batchX.shape))\n",
    "                        \n",
    "                        # Step1 : Preprocess the Data\n",
    "                        preprocessedData = self.runPreprocessor(dataIN=batchX, sess=sess)\n",
    "                            \n",
    "                        # Since we improve on our previous prediction, there can be cases where the network has learned a good enough\n",
    "                        # decision boundary (for a batch) and is unable to find hard negative for the triplet selection. In such a case\n",
    "                        # the network would return an empty array, which would raise a run time exception during the graph is computed.\n",
    "                        # For such cases we would except an exception, and let the graph proceed. \n",
    "                        try:\n",
    "                            opt, batch_loss = sess.run([trn_embed_graph['optimizer'], \n",
    "                                                        trn_embed_graph['loss']], \n",
    "                                                        feed_dict={trn_embed_graph['inpTensor']:preprocessedData})\n",
    "                        except Exception:\n",
    "                            logging.info('Exception Raised! Check the log file and confirm if the exception is becasue of empty triplet array. If not then debugg it :)')       \n",
    "                            logging.info(\"Fold = %s, Epoch = %s, Loss = %s\", \n",
    "                                         str(self.nFold), str(self.epoch), \"{:.6f}\".format(batch_loss))\n",
    "                            \n",
    "                        print(\"Fold: \" + str(self.nFold) + \n",
    "                              \", Epoch= \" + str(self.epoch) + \n",
    "                              \", Loss= \" + \"{:.6f}\".format(batch_loss))\n",
    "                    \n",
    "                    save_path = saver.save(sess, os.path.join(path_dict['checkpoint_path'], \"distinct_stratified_model.ckpt\"))\n",
    "                    \n",
    "\n",
    "                    # Now that we have updated our parameters (weights and biases), we would\n",
    "                    # fetch the embeddings using the updated parameter and train-test model\n",
    "                    # to get an accuracy. Accuracy per epoch is now a good way to go\n",
    "                    self.setNewWeights(sess) # replace the last layer's inception weights with leared finetuned weights\n",
    "                    \n",
    "                    # TRAIN, GET TRAINING PREDICTION AND ACCURACY\n",
    "                    trnX_ = trnX.reshape(-1, trnX.shape[2], trnX.shape[3], trnX.shape[4]) # accumulate all batches\n",
    "                    trnY_ = trnY.flatten()\n",
    "                    train_labels, _ = self.train(trnX_, trnY_, sess)\n",
    "                    tr_acc = self.accuracy(y=trnY_, y_hat=train_labels)\n",
    "                    print (tr_acc)\n",
    "                    \n",
    "                    # GET CROSS VALIDATION PREDICTION AND ACCURACY\n",
    "                    cv_labels, _ = self.cvalid(cvX, sess)\n",
    "                    cv_acc = self.accuracy(y=cvY, y_hat=cv_labels)\n",
    "                    print (cv_acc)\n",
    "                    \n",
    "#                     break\n",
    "\n",
    "                break\n",
    "\n",
    "objExec = Execute(params=moduleWeightDict, myNet=myNet, embeddingType='finetune')\n",
    "objExec.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO NOTE:\n",
    "\n",
    "The triplet selection is differnt for every differnt run even after having seed. This could be because small changes in embedding may initiate different triplet seletion. Embedding can be different becasue we have many random preprocessing steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGH\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 3, 5]\n",
      "5\n",
      "[[[[ 10.41702175  10.72032452  10.00011444  10.30233288  10.14675617]\n",
      "   [ 10.09233856  10.18626022  10.34556103  10.39676762  10.53881645]\n",
      "   [ 10.41919422  10.68521976  10.20445251  10.87811756  10.02738762]]]]\n",
      "[ 10.30951786  10.5306015   10.18337631  10.52573872  10.23765373]\n",
      "[5]\n",
      "[ 0.02358428  0.05949085  0.020111    0.06357152  0.0477244 ]\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "tfdata = tf.cast(np.random.rand(1,1,3,5) + 10, dtype=tf.float32)\n",
    "print (tfdata.get_shape().as_list())\n",
    "print (tfdata.get_shape()[-1])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batchMean, batchVar = tf.nn.moments(tfdata, axes=[0,1,2], name=\"moments\")\n",
    "    print (tfdata.eval())\n",
    "    print (batchMean.eval())\n",
    "    print (batchMean.get_shape().as_list())\n",
    "    print (batchVar.eval())\n",
    "    print (batchVar.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3,4])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'InvalidArgumentError' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Index out of range using input dim 1; input has only 1 dims\n\t [[Node: strided_slice = StridedSlice[Index=DT_INT32, T=DT_INT64, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](PyFunc, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-810e2789272e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Index out of range using input dim 1; input has only 1 dims\n\t [[Node: strided_slice = StridedSlice[Index=DT_INT32, T=DT_INT64, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](PyFunc, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)]]\n\nCaused by op 'strided_slice', defined at:\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-810e2789272e>\", line 8, in <module>\n    y_1 = tf.add(y[:,0], 1)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 538, in _SliceHelper\n    name=name)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 706, in strided_slice\n    shrink_axis_mask=shrink_axis_mask)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5430, in strided_slice\n    name=name)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Index out of range using input dim 1; input has only 1 dims\n\t [[Node: strided_slice = StridedSlice[Index=DT_INT32, T=DT_INT64, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](PyFunc, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-810e2789272e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'dasdsdsdsdsdsdsds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'InvalidArgumentError' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "reset_graph()\n",
    "def my_func(x):\n",
    "    return [x]\n",
    "\n",
    "inp = tf.placeholder(tf.int64)\n",
    "y = tf.py_func(my_func, [inp], tf.int64)\n",
    "y_1 = tf.add(y[:,0], 1)\n",
    "# print (len(y))#.get_shape())\n",
    "\n",
    "# a = np.array([[1,2,3],[4,5,6],[6,7,8]])\n",
    "a = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    try:\n",
    "        yy = sess.run([y_1],feed_dict={inp:a})\n",
    "        print (yy)\n",
    "    except InvalidArgumentError:\n",
    "        print ('dasdsdsdsdsdsdsds')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
