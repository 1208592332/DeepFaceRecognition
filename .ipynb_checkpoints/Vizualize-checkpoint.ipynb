{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualize Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from skimage import transform, io, img_as_uint\n",
    "from scipy import ndimage, misc\n",
    "picPath = '/Users/sam/All-Program/App-DataSet/Deep-Neural-Nets/Models/FaceRecognition/camera_0.jpg'\n",
    "\n",
    "picPath = \"/Users/sam/All-Program/App-DataSet/DeepFaceRecognition/original/\"\n",
    "resizedPath = \"/Users/sam/All-Program/App-DataSet/DeepFaceRecognition/resized/\"\n",
    "\n",
    "\n",
    "def readImage(imagePath, resize=96):\n",
    "    '''\n",
    "        The input data is is in the shape of [nh, nw, nc], convert it to [nc, nh, nw]\n",
    "    '''\n",
    "    image = misc.imread(picPath)\n",
    "    img = np.around(np.transpose(image, (2,0,1))/255.0, decimals=12) #(2,0,1) = [nc, nh, nw]\n",
    "    print (image.shape)\n",
    "    \n",
    "# def resize(folderPath):\n",
    "folderPath = picPath\n",
    "people = [folder for folder in os.listdir(folderPath) if len(folder.split(\".\")) == 1]\n",
    "\n",
    "imageOrig = []\n",
    "imageRshape = []\n",
    "for name in people:\n",
    "#     if name != 'jetha':\n",
    "#         continue\n",
    "    outPersonPath = os.path.join(resizedPath, name)\n",
    "    if not os.path.exists(outPersonPath):\n",
    "        os.makedirs(outPersonPath)\n",
    "    personPath = os.path.join(folderPath, name)\n",
    "    imagePathList = [os.path.join(personPath,images) for images in os.listdir(personPath) if images.split(\".\")[1] == 'jpg']\n",
    "    for num, imagePath in enumerate(imagePathList):\n",
    "        print (imagePath)\n",
    "        image = ndimage.imread(imagePath, mode='RGB')\n",
    "\n",
    "        imageResized = misc.imresize(image, (96,96))\n",
    "#         imageList = io.imshow(imageResized)\n",
    "        io.imsave(os.path.join(outPersonPath, '%s.jpg'%str(num)), img_as_uint(imageResized))\n",
    "#         io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with sess.as_default():\n",
    "    imgPath = \"/Users/sam/All-Program/App-DataSet/DeepFaceRecognition/original/sam/20171006_210052.jpg\"\n",
    "    fileQueue = tf.train.string_input_producer(tf.train.match_filenames_once(imgPath))\n",
    "    image_reader = tf.WholeFileReader()\n",
    "    _, image_file = image_reader.read(fileQueue)\n",
    "    image =  tf.image.decode_jpeg(image_file)\n",
    "    print (image.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
