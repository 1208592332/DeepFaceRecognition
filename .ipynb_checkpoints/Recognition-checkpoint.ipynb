{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from DataPrep.data_io import DataFormatter\n",
    "from nn.load_params import layer_name, convShape, getWeights\n",
    "from nn.utils import getTriplets, tripletLoss\n",
    "# from nn.model import initNetwork\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logfile.log\", filemode=\"w\",\n",
    "                    format=\"%(asctime)-15s %(levelname)-8s %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET INCEPTION WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parentPath = \"/Users/sam/All-Program/App-DataSet/Deep-Neural-Nets/Models/FaceNet-Inception\"\n",
    "moduleWeightDict = getWeights(parentPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZE NETWORK WITHWEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorDict = initNetwork(moduleWeightDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD THE BATCH DATA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def loss(encodingDict, img_per_labels, num_labels, alpha):\n",
    "    '''\n",
    "        Implementing the Tensor Graph for Triplet loss function.\n",
    "        The output tripletIDX is a numpy ND array.\n",
    "    '''\n",
    "    tripletIDX = tf.py_func(getTriplets, \n",
    "                            [encodingDict['output'], img_per_label, num_labels, alpha], \n",
    "                            tf.int64)\n",
    "    loss = tripletLoss(\n",
    "        tf.gather(tf.cast(encodingDict['output'], dtype=tf.float32), tripletIDX[:,0]),\n",
    "        tf.gather(tf.cast(encodingDict['output'], dtype=tf.float32), tripletIDX[:,1]),\n",
    "        tf.gather(tf.cast(encodingDict['output'], dtype=tf.float32), tripletIDX[:,2]),\n",
    "        alpha=0.2)\n",
    "    encodingDict['loss'] = loss\n",
    "    return encodingDict\n",
    "\n",
    "def optimize(encodingDict):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(encodingDict['loss'])\n",
    "    encodingDict['optimizer'] = optimizer\n",
    "    return encodingDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getBatchTriplets():\n",
    "#     getTriplets_TF(batch_embedding, img_per_label, num_labels, alpha=0.01)\n",
    "    \n",
    "from nn.model import getModel_FT, getModel\n",
    "def initNetwork(weightDict, isTrainable=False):\n",
    "    logging.info('INITIALIZING THE NETWORK !! ...............................')\n",
    "    if not isTrainable:\n",
    "        encodingDict = getModel([96, 96, 3], params=weightDict)\n",
    "    else:\n",
    "        img_per_label = 6\n",
    "        num_labels = 3\n",
    "        alpha = 0.01\n",
    "        encodingDict = getModel_FT([96, 96, 3], params=weightDict)   \n",
    "        encodingDict = loss(encodingDict, img_per_label, num_label, alpha)\n",
    "        encodingDict = optimize(encodingDict)\n",
    "    return encodingDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input data (X) is:  (10, 18, 96, 96, 3)\n",
      "The shape of input data (Y) is:  (10, 18)\n",
      "Unique labels in dataY is:  [ 0.  1.  2.]\n",
      "Label dict:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': <tf.Tensor 'InceptionFC_FT/L2_norm:0' shape=(?, 128) dtype=float32>, 'optimizer': <tf.Operation 'Adam' type=NoOp>, 'inpTensor': <tf.Tensor 'Placeholder:0' shape=(?, 96, 96, 3) dtype=float32>, 'loss': <tf.Tensor 'TripletLoss/Sum_2:0' shape=<unknown> dtype=float32>}\n",
      "@@@@\n",
      "8.05707\n",
      "#########################\n",
      "@@@@\n",
      "9.45204\n",
      "#########################\n",
      "@@@@\n",
      "9.45865\n",
      "#########################\n",
      "@@@@\n",
      "9.1883\n",
      "#########################\n",
      "@@@@\n",
      "7.87027\n",
      "#########################\n",
      "@@@@\n",
      "6.95968\n",
      "#########################\n",
      "@@@@\n",
      "6.84956\n",
      "#########################\n",
      "@@@@\n",
      "7.05621\n",
      "#########################\n",
      "@@@@\n",
      "6.6409\n",
      "#########################\n",
      "@@@@\n",
      "7.85195\n",
      "#########################\n"
     ]
    }
   ],
   "source": [
    "path_to_batch_data = '/Users/sam/All-Program/App-DataSet/DeepFaceRecognition/data_models/batch_img_arr'\n",
    "batch_file_name = 'random_batches.pickle'\n",
    "\n",
    "dataX, dataY, labelDict = DataFormatter.getPickleFile(folderPath=path_to_batch_data, \n",
    "                                                      picklefileName=batch_file_name, getStats=True)\n",
    "\n",
    "\n",
    "reset_graph()\n",
    "encodingDict = initNetwork(moduleWeightDict, isTrainable=True)\n",
    "print (encodingDict)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for batchNum, batchX in enumerate(dataX):\n",
    "        batchY = dataY[batchNum, :]\n",
    "        opt, batch_loss = sess.run([encodingDict['optimizer'], \n",
    "                                   encodingDict['loss']], \n",
    "                                  feed_dict={encodingDict['inpTensor']:batchX})\n",
    "#         print (opt)\n",
    "        print('@@@@')\n",
    "        print (batch_loss)\n",
    "        print ('#########################')\n",
    "#         embeddings = embeddings[0]\n",
    "        \n",
    "#         a\n",
    "#         tripletIndexArr = np.array(tripletIndexArr).reshape(-1,3)\n",
    "#         a_idxs = tripletIndexArr[:,0].flatten()\n",
    "#         p_idxs = tripletIndexArr[:,1].flatten()\n",
    "#         n_idxs = tripletIndexArr[:,2].flatten()\n",
    "#         loss = tripletLoss(tf.gather(tf.cast(embeddings, dtype=tf.float32), a_idxs),\n",
    "#                            tf.gather(tf.cast(embeddings, dtype=tf.float32), p_idxs),\n",
    "#                            tf.gather(tf.cast(embeddings, dtype=tf.float32), n_idxs), alpha=0.2)\n",
    "#         print (loss.eval())\n",
    "        \n",
    "        \n",
    "#         pritn ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "tfdata = tf.cast(np.random.rand(1,1,3,5) + 10, dtype=tf.float32)\n",
    "print (tfdata.get_shape().as_list())\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batchMean, batchVar = tf.nn.moments(tfdata, axes=[0,1,2], name=\"moments\")\n",
    "    print (tfdata.eval())\n",
    "    print (batchMean.eval())\n",
    "    print (batchMean.get_shape().as_list())\n",
    "    print (batchVar.eval())\n",
    "    print (batchVar.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3,4])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 3)\n",
      "(3, 3)\n",
      "[[1 2 3]\n",
      " [3 2 4]]\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
    "                 [[3, 3, 3], [4, 4, 4]],\n",
    "                 [[5, 5, 5], [6, 6, 6]]])\n",
    "\n",
    "a = tf.constant([[1,2,3],[3,2,4],[1,1,4]])\n",
    "print(t.shape)\n",
    "print (a.shape)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print (tf.gather(a, [0, 1]).eval())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3558921769"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow(0.3426 - 0.927, 2) + pow(0.7484-0.62853, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
