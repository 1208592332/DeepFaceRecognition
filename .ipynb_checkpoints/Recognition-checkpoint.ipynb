{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS SUMMARY:\n",
    "-------------\n",
    "\n",
    "For any deep learning problem, it is important to have more and more data. Our analysis, infact shows that this is true. Additionally, other stuffs like Exponential weighted average Batch normalization makes the model more robust.\n",
    "\n",
    "* First, we implement a simple base line model where we simple get embeddings for each image in the train and cv set. Note, we use the weights from the pretrained inception model from Face Net. The embeddings(features) were trained using a SVM classifier and the cross validation set was tested. The avg validation accuracy for 10 Fold was appx 35%, which is not a very great number.\n",
    "\n",
    "* Due to bad outcomes from the base line model, we try to finetune the last layer of inception net with 90 images (30 image each label) and without exp weighted batch normalization. The accuracy of the model was very poor, jumping between 10% to 60%.\n",
    "\n",
    "* Then we added more data 180 images (+30 images each label) the model performed little better than the previous model. But still the outcomes were inconsistent.\n",
    "\n",
    "* Adding Exponential batch norm , made the results consistent accross runs. But we still had accuracy droping to 10%-20% per batch.\n",
    "\n",
    "* We added more data 300 images (100 images per label). The results were far batter than the previous run and were also consistent. The results at this point were consistent. Cross validation 1 batch accuracy was between 60 to 70 percent. The problem however was that the accuracy decreased after epoch 6. Early stopping could help.\n",
    "\n",
    "* After adding learning rate decay, as expected the cross validation accuracy gets more consistent accross different batches and produces a accuracy of 83% at epoch 10.\n",
    "\n",
    "*\n",
    "\n",
    "\n",
    "#### TO NOTE:\n",
    "\n",
    "The triplet selection is differnt for every differnt run even after having seed. This could be because small changes in embedding may initiate different triplet seletion. Embedding can be different becasue we have many random preprocessing steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from data_transformer.data_formatter import DataFormatter\n",
    "from data_transformer.preprocess import Preprocessing\n",
    "\n",
    "from data_transformer.data_prep import DataIO, genDistinctStratifiedBatches, genRandomStratifiedBatches\n",
    "from nn.load_params import layer_name, convShape, getWeights\n",
    "from nn.utils import getTriplets, tripletLoss\n",
    "from train_test.model import *\n",
    "from train_test.classify import SVM\n",
    "from config import path_dict\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logfile.log\", filemode=\"w\",\n",
    "                    format=\"%(asctime)-15s %(levelname)-8s %(message)s\")\n",
    "\n",
    "training = False\n",
    "verification = False\n",
    "create_batches = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE TIME RUN: \n",
    "------------\n",
    "#### INPUT :  Folder path with images of several people, ensure the image folders are named with the person name\n",
    "#### OUTPUT: Dumps a pickle file with three keys, dataX, dataY, labelDict. \n",
    "            * dataX: images converted into nd array\n",
    "            * dataY: for each record of nd array, Labels are numerical (1,2,3,4,5)\n",
    "            * labelDict: Contains the label corresponding to person name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if training:\n",
    "    objDP = DataFormatter(path_dict['parent_path'], 'training')\n",
    "    objDP.createResizedData()\n",
    "    dataX, dataY, labelDict = objDP.imageToArray()\n",
    "    DataFormatter.dumpPickleFile(dataX, dataY, labelDict,\n",
    "                               folderPath=os.path.join(path_dict['data_model_path']),\n",
    "                               picklefileName='training_imgarr.pickle')\n",
    "if verification:\n",
    "    objDP = DataFormatter(path_dict['parent_path'], 'verification')\n",
    "    objDP.createResizedData()\n",
    "    dataX, dataY, labelDict = objDP.imageToArray()\n",
    "    DataFormatter.dumpPickleFile(dataX, dataY, labelDict,\n",
    "                               folderPath=os.path.join(path_dict['data_model_path']),\n",
    "                               picklefileName='verification_imgarr.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE RANDOM BATCHES:\n",
    "----------------\n",
    "#### INPUT: Image nd array as input  [num_images, imgX, imgY, num_channels]\n",
    "#### OUTPUT: Outputs a pickle file with shape [num_batches, num_image_per_batch, imgX, imgY, num_channels]\n",
    "\n",
    "       *  We would wanna do stocastic descent for minibatches and update the parameters perbatch. This module attempts to create stratified batches (each batch would have equal distribution of labels). \n",
    "       \n",
    "       * when genDistinctStratifiedBatches. The images in the batched would be distinct (would not repeat)\n",
    "       * when genRandomStratifiedBatches. No seed is set for shuffling. So Images in different batches may repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if create_batches:\n",
    "    trainX, trainY, trainLabelDict = DataIO.getPickleFile(path_dict['data_model_path'],\n",
    "                                                                 'training_imgarr.pickle')\n",
    "    verX, verY, verLabelDict = DataIO.getPickleFile(path_dict['data_model_path'],\n",
    "                                                           'verification_imgarr.pickle')\n",
    "    print(trainX.shape, trainY.shape)\n",
    "    print(verX.shape, verY.shape)\n",
    "    genDistinctStratifiedBatches(trainX, trainY,\n",
    "                          fileName='distinct_stratified_batches.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## RESET TENSORFLOW GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET INCEPTION WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "moduleWeightDict = getWeights(path_dict['inception_nn4small_weights_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO's:\n",
    "\n",
    "1. Remove the random weight initialiazer for the last layer, and initialize it \n",
    "   with the inception net weights.  **DONE**\n",
    "\n",
    "2. implement a module to save weights as checkpoints to the disk.  **DONE**\n",
    "\n",
    "3. create a function to toggle between Random weight initializer, Inception net weight initializer \n",
    "   and using the saved checkpoint for the last Inception layer. **DONE**\n",
    "   \n",
    "4 : REMEBER TO STORE THE exponential weighted average of mean and variable in the batch normalization \n",
    "      fine tune function. SET THESE AS A VARIABLE (LOOK AT CIFAR CODE FOR HELP) **DONE**\n",
    " \n",
    "5. Add more images.\n",
    "\n",
    "6. Create a complete workflow train the network and perform cross validation: **DONE**\n",
    "\n",
    "7. Store 1 image encodings for the 3-4 labels you have.\n",
    "\n",
    "8. For a new image, pass the image throught network, get the encoding and see which is the most closest face using the encoding from the step 6.\n",
    "\n",
    "9. Try :\n",
    "    1. SVM classfication on embedding feature space: Get cross validation accuracy: **DONE**\n",
    "    2. Softmax classification on embedding feature space: Get cross validation accuracy. \n",
    "    \n",
    "10. The triplet selection now has, random selection of Hard negative. Having random selection makes it difficult to adjust parameters. So make is generated by a sedd, but the sees itself should be generated randomly via a different sees. Since having the same seeed decide a triplet would be problematic becasue the same hard negative would always be selected. **DONE**\n",
    "\n",
    "11. Add learning rate decay. **DONE**\n",
    "\n",
    "12. Softmax classifier\n",
    "\n",
    "13. Add baseline model, using only pretrained weights: **DONE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE MODEL:\n",
    "---------------\n",
    "\n",
    "### When using Pretrained weights for all layers\n",
    "* We see that the training accuracy is pretty high (which would be the case) but the cross validation accuracy every fold is at an average 35% which is very less but better than random guessing. We know that convolutional layer at later stage are able to learn very complex features. The inception net weights were trained on a dataset that is different from the dataset being used here despite both being images of faces. Hence the model would overfit.\n",
    "\n",
    "* There fore it is suggested to finetune last few layers of the network and relearning the weights fof only last few layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input data (X) is:  (10, 30, 96, 96, 3)\n",
      "The shape of input data (Y) is:  (10, 30)\n",
      "Unique labels in dataY is:  [ 0.  1.  2.]\n",
      "Label dict:  None\n",
      "(270, 96, 96, 3) 270\n",
      "Fold: 1, Train acc = 0.848148148148 \n",
      "Fold: 1, CV acc = 0.333333333333 \n",
      "(270, 96, 96, 3) 270\n",
      "Fold: 2, Train acc = 0.855555555556 \n",
      "Fold: 2, CV acc = 0.366666666667 \n",
      "(270, 96, 96, 3) 270\n",
      "Fold: 3, Train acc = 0.862962962963 \n",
      "Fold: 3, CV acc = 0.466666666667 \n",
      "(270, 96, 96, 3) 270\n",
      "Fold: 4, Train acc = 0.855555555556 \n",
      "Fold: 4, CV acc = 0.333333333333 \n",
      "(270, 96, 96, 3) 270\n",
      "Fold: 5, Train acc = 0.862962962963 \n",
      "Fold: 5, CV acc = 0.333333333333 \n",
      "(270, 96, 96, 3) 270\n",
      "Fold: 6, Train acc = 0.844444444444 \n",
      "Fold: 6, CV acc = 0.333333333333 \n",
      "(270, 96, 96, 3) 270\n",
      "Fold: 7, Train acc = 0.877777777778 \n",
      "Fold: 7, CV acc = 0.333333333333 \n",
      "(270, 96, 96, 3) 270\n",
      "Fold: 8, Train acc = 0.866666666667 \n",
      "Fold: 8, CV acc = 0.333333333333 \n",
      "(270, 96, 96, 3) 270\n",
      "Fold: 9, Train acc = 0.862962962963 \n",
      "Fold: 9, CV acc = 0.333333333333 \n",
      "(270, 96, 96, 3) 270\n",
      "Fold: 10, Train acc = 0.881481481481 \n",
      "Fold: 10, CV acc = 0.333333333333 \n",
      "Total 10 Folds, Avg Train acc = 0.862, Avg CV acc = 0.35 \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "import config\n",
    "from config import myNet\n",
    "\n",
    "which_file = 'distinct_stratified_batches.pickle'\n",
    "checkpoint_file_name = 'distinct_stratified_model'\n",
    "\n",
    "class Execute():\n",
    "    def __init__(self, params, myNet, embeddingType='finetune'):\n",
    "        self.params = params\n",
    "        self.embeddingType = embeddingType\n",
    "        self.myNet = myNet\n",
    "        self.myNet['learning_rate'] = 0.0001\n",
    "        \n",
    "    def runPreprocessor(self, dataIN, sess):\n",
    "        preprocessedData = np.ndarray(shape=(dataIN.shape), dtype='float32')\n",
    "        print (preprocessedData.shape, dataIN.shape[0])\n",
    "        for numImage in np.arange(dataIN.shape[0]):\n",
    "            feed_dict = {\n",
    "                self.preprocessGraphDict['imageIN']:dataIN[numImage,:]\n",
    "            }\n",
    "            preprocessedData[numImage,:] = sess.run(self.preprocessGraphDict['imageOUT'],\n",
    "                                                      feed_dict=feed_dict)\n",
    "        return preprocessedData\n",
    "        \n",
    "    def train(self, trnX_, trnY_, sess):\n",
    "        '''\n",
    "            1. Preprocess the image and directly get the embedding without finetuning.\n",
    "            3. Use the embeddings as feature for a classifier (svm/softmax)\n",
    "            4. Classify faces using the embeddings.\n",
    "        '''\n",
    "        trainEmbedGraph = getEmbeddings(self.myNet['image_shape'], self.params)\n",
    "        embeddings = sess.run(trainEmbedGraph['output'], \n",
    "                              feed_dict={trainEmbedGraph['inpTensor']:trnX_})\n",
    "        logging.info('Training Embeddings shape %s', embeddings.shape)\n",
    "        obj_svm = SVM()\n",
    "        obj_svm.train(embeddings, labels=trnY_, \n",
    "                      model_name='baseline_nFold_%s'%(str(self.nFold)))\n",
    "        train_labels, train_label_prob = obj_svm.classify(embeddings, \n",
    "                                model_name='baseline_nFold_%s'%(str(self.nFold)))\n",
    "        return train_labels, train_label_prob\n",
    "    \n",
    "    def cvalid(self, cvX_, sess):\n",
    "        embedGraph = getEmbeddings(self.myNet['image_shape'], self.params)\n",
    "        embeddings = sess.run(embedGraph['output'], \n",
    "                              feed_dict={embedGraph['inpTensor']:cvX_})\n",
    "        logging.info('Cross validation Embeddings shape %s', embeddings.shape)\n",
    "        obj_svm = SVM()\n",
    "        cv_labels, cv_label_prob = obj_svm.classify(embeddings, \n",
    "                                             model_name='baseline_nFold_%s'%(str(self.nFold)))\n",
    "        return cv_labels, cv_label_prob\n",
    "    \n",
    "    def accuracy(self, y, y_hat):\n",
    "        return np.mean(np.equal(y_hat, y))\n",
    "\n",
    "    def run(self):\n",
    "        # GET THE BATCH DATA FROM THE DISK\n",
    "        dataX, dataY, labelDict = DataFormatter.getPickleFile(\n",
    "            folderPath=path_dict['batchFolderPath'], picklefileName=which_file, getStats=True\n",
    "        )\n",
    "        trnBatch_idx = [list(np.setdiff1d(np.arange(len(dataX)), np.array(i))) for i in  np.arange(len(dataX))]\n",
    "        cvBatch_idx = [i for i in  np.arange(len(dataX))]\n",
    "        logging.info('dataX.shape = %s, dataY.shape = %s',str(dataX.shape), str(dataY.shape))\n",
    "\n",
    "        # Reset graph to do a fresh start\n",
    "        reset_graph()\n",
    "#         trn_embed_graph = trainEmbeddings(moduleWeightDict,init_wght_type='random')\n",
    "        self.preprocessGraphDict = Preprocessing().preprocessImageGraph(\n",
    "                                                            imageShape=self.myNet[\"image_shape\"])\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            avg_tr_acc = 0\n",
    "            avg_cv_acc = 0\n",
    "            # LOOP FOR N-FOLD CROSS VALIDATION\n",
    "            for nFold, (trn_batch_idx, cv_batch_idx) in enumerate(zip(trnBatch_idx, cvBatch_idx)):\n",
    "                self.nFold = nFold + 1\n",
    "                logging.info('RUNNING : %s FOLD ...........................', str(self.nFold))\n",
    "                trnX = dataX[trn_batch_idx,:]\n",
    "                trnY = dataY[trn_batch_idx,:]\n",
    "                cvX = dataX[cv_batch_idx,:]\n",
    "                cvY = dataY[cv_batch_idx,:]\n",
    "                logging.info('trnX.shape = %s, trnY.shape = %s, cvX.shape = %s, cvY.shape = %s', \n",
    "                      str(trnX.shape), str(trnY.shape), str(cvX.shape), str(cvY.shape))\n",
    "                \n",
    "                # TRAIN, GET TRAINING PREDICTION AND ACCURACY\n",
    "                trnX_ = trnX.reshape(-1, trnX.shape[2], trnX.shape[3], trnX.shape[4]) # accumulate all batches\n",
    "                preprocessedData = self.runPreprocessor(dataIN=trnX_, sess=sess)\n",
    "                logging.info('Preprocessed Data.shape = %s', str(preprocessedData.shape))\n",
    "                trnY_ = trnY.flatten()\n",
    "                train_labels, _ = self.train(preprocessedData, trnY_, sess)\n",
    "                tr_acc = self.accuracy(y=trnY_, y_hat=train_labels)\n",
    "                avg_tr_acc = avg_tr_acc + tr_acc\n",
    "                print (\"Fold: %s, Train acc = %s \"%(str(self.nFold) , str(tr_acc)))\n",
    "\n",
    "                # GET CROSS VALIDATION PREDICTION AND ACCURACY\n",
    "                cv_labels, _ = self.cvalid(cvX, sess)\n",
    "                cv_acc = self.accuracy(y=cvY, y_hat=cv_labels)\n",
    "                avg_cv_acc = avg_cv_acc + cv_acc\n",
    "                print (\"Fold: %s, CV acc = %s \"%(str(self.nFold) , str(cv_acc)))\n",
    "                    \n",
    "#                     break\n",
    "        print (\"Total %s Folds, Avg Train acc = %s, Avg CV acc = %s \"%(str(self.nFold) , \n",
    "                                                                       str(round(avg_tr_acc/self.nFold, 3)), \n",
    "                                                                       str(round(avg_cv_acc/self.nFold, 3)))\n",
    "              )\n",
    "\n",
    "objExec = Execute(params=moduleWeightDict, myNet=myNet, embeddingType='finetune')\n",
    "objExec.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINE TUNE MODEL:\n",
    "------------\n",
    "\n",
    "### When Fine tuning the weights of the last two layers\n",
    "* When we fine tune only the last inception layer of the new and use the same configured SVM classifier, we see that the cross validation accuracy has increased by more that 25%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input data (X) is:  (10, 30, 96, 96, 3)\n",
      "The shape of input data (Y) is:  (10, 30)\n",
      "Unique labels in dataY is:  [ 0.  1.  2.]\n",
      "Label dict:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sess_exec() takes 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1c89d2a072a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0mobjExec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyNet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddingType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'finetune'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m \u001b[0mobjExec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweightsIN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmoduleWeightDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-1c89d2a072a9>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, weightsIN)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 imageShape=self.myNet[\"image_shape\"])\n\u001b[1;32m    187\u001b[0m             \u001b[0;31m# EXECUTE THE SESSION FOR THE CURRENT FOLD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mtr_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrnX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrnY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresetWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweightsIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sess_exec() takes 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "import config\n",
    "from config import myNet\n",
    "\n",
    "which_file = 'distinct_stratified_batches.pickle'\n",
    "checkpoint_file_name = 'distinct_stratified_model'\n",
    "\n",
    "'''\n",
    "dataX = [num_batches, image_per_batch, image_x, image_y, image_channels]\n",
    "dataY = [num_batches, labels]\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class Execute():\n",
    "    def __init__(self, myNet, embeddingType='finetune'):\n",
    "        self.embeddingType = embeddingType\n",
    "        self.myNet = myNet\n",
    "        self.myNet['learning_rate'] = 0.0001\n",
    "    \n",
    "    def runPreprocessor(self, dataIN, sess):\n",
    "        preprocessedData = np.ndarray(shape=(dataIN.shape), dtype='float32')\n",
    "        for numImage in np.arange(dataIN.shape[0]):\n",
    "            feed_dict = {\n",
    "                self.preprocessGraphDict['imageIN']: dataIN[numImage, :]\n",
    "            }\n",
    "            preprocessedData[numImage, :] = sess.run(self.preprocessGraphDict['imageOUT'],\n",
    "                                                     feed_dict=feed_dict)\n",
    "        return preprocessedData\n",
    "    \n",
    "    def resetWeights(self, weightsIN):\n",
    "        logging.info('RESETTING WEITHGS WITH PRE-TRAINED WEIGHTS .........')\n",
    "        self.weights = weightsIN\n",
    "    \n",
    "    def setNewWeights(self, sess):\n",
    "        logging.info('UPDATING WEITHGS WITH FINETUNED WEIGHTS .........')\n",
    "        #         trainableVars = tf.get_collection(ops.GraphKeys.TRAINABLE_VARIABLES)\n",
    "        if self.embeddingType == 'finetune':\n",
    "            for learned_vars in config.finetune_variables:\n",
    "                scope, name = learned_vars.split(':')[0].split('/')\n",
    "                if len(self.weights[scope][name]) != 0:\n",
    "                    var_ = sess.run(learned_vars)\n",
    "                    logging.info('Updating param with scope %s and name %s and shape %s with shape %s',\n",
    "                                 str(scope), str(name), str(self.weights[scope][name].shape), str(var_.shape))\n",
    "                    self.weights[scope][name] = var_\n",
    "                else:\n",
    "                    raise ValueError('It seems that the scope %s or variable %s didnt exist in the dictionary ' % (\n",
    "                        str(scope), str(name)))\n",
    "    \n",
    "    def train(self, trnX_, trnY_, sess):\n",
    "        '''\n",
    "            1. Make the use of getEmbedding to get the graph with last layer parameter updated with the \n",
    "            fine tuned weights.\n",
    "            2. Get the new embedding for batch/epoch using the computation graph\n",
    "            3. Use the embeddings as feature for a classifier (svm/softmax)\n",
    "            4. Classify faces using the new embeddings.\n",
    "        '''\n",
    "        trainEmbedGraph = getEmbeddings(self.myNet['image_shape'], self.weights)\n",
    "        embeddings = sess.run(trainEmbedGraph['output'],\n",
    "                              feed_dict={trainEmbedGraph['inpTensor']: trnX_})\n",
    "        logging.info('Training Embeddings shape %s', embeddings.shape)\n",
    "        obj_svm = SVM()\n",
    "        obj_svm.train(embeddings, labels=trnY_,\n",
    "                      model_name='nFold_%s_batch_%s' % (str(self.nFold), str(self.epoch)))\n",
    "        train_labels, train_label_prob = obj_svm.classify(embeddings,\n",
    "                                                          model_name='nFold_%s_batch_%s' % (\n",
    "                                                              str(self.nFold), str(self.epoch)))\n",
    "        return train_labels, train_label_prob\n",
    "    \n",
    "    def cvalid(self, cvX_, sess):\n",
    "        embedGraph = getEmbeddings(self.myNet['image_shape'], self.weights)\n",
    "        embeddings = sess.run(embedGraph['output'],\n",
    "                              feed_dict={embedGraph['inpTensor']: cvX_})\n",
    "        logging.info('Cross validation Embeddings shape %s', embeddings.shape)\n",
    "        obj_svm = SVM()\n",
    "        cv_labels, cv_label_prob = obj_svm.classify(embeddings,\n",
    "                                                    model_name='nFold_%s_batch_%s' % (str(self.nFold), str(self.epoch)))\n",
    "        return cv_labels, cv_label_prob\n",
    "    \n",
    "    def accuracy(self, y, y_hat):\n",
    "        return np.mean(np.equal(y_hat, y))\n",
    "    \n",
    "    #     def test(self, tstGraph, testBatch, sess):\n",
    "    #         # METHOD 2: TO get weights is form of Tensors\n",
    "    #         a = saver.restore(sess, os.path.join(checkpoint_path, \"model.ckpt\"))\n",
    "    #         trainableVars = tf.get_collection(ops.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    #         testDict = getFineTunedEmbeddings([96,96,3], moduleWeightDict, trainableVars, sess)\n",
    "    #         embeddings = sess.run([tstGraph['output']], feed_dict={'inpTensor':testBatch})\n",
    "    #         return embeddings\n",
    "    \n",
    "    def sess_exec(self, trnX, trnY, cvX, cvY):\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            checkpoints = [ck for ck in os.listdir(path_dict['checkpoint_path']) if ck != '.DS_Store']\n",
    "            if len(checkpoints) > 0 and self.myNet['use_checkpoint']:\n",
    "                saver.restore(sess, os.path.join(path_dict['checkpoint_path'],\n",
    "                                                 \"distinct_stratified_model.ckpt\"))\n",
    "            \n",
    "            for epoch in np.arange(10):\n",
    "                self.epoch = epoch + 1\n",
    "                logging.info('RUNNING : %s EPOCH ........................', str(self.epoch))\n",
    "                # Below loop will minimize the triplet loss and update the parameters\n",
    "                for batchNum, batchX in enumerate(trnX[0:len(trnX), :]):\n",
    "                    logging.info('RUNNING BATCH %s for shape = %s', str(batchNum + 1), str(batchX.shape))\n",
    "                    \n",
    "                    # Step1 : Preprocess the Data\n",
    "                    preprocessedData = self.runPreprocessor(dataIN=batchX, sess=sess)\n",
    "                    \n",
    "                    # Since we improve on our previous prediction, there can be cases where the network has learned a\n",
    "                    #  good enough\n",
    "                    # decision boundary (for a batch) and is unable to find hard negative for the triplet selection. \n",
    "                    # In such a case\n",
    "                    # the network would return an empty array, which would raise a run time exception during the \n",
    "                    # graph is computed.\n",
    "                    # For such cases we would except an exception, and let the graph proceed. \n",
    "                    try:\n",
    "                        opt, batch_loss, lr = sess.run([self.trn_embed_graph['optimizer'],\n",
    "                                                        self.trn_embed_graph['loss'],\n",
    "                                                        self.trn_embed_graph['learning_rate']],\n",
    "                                                       feed_dict={self.trn_embed_graph['inpTensor']: preprocessedData})\n",
    "                    except Exception:\n",
    "                        logging.info(\n",
    "                                'Exception Raised! Check the log file and confirm if the exception is becasue of empty '\n",
    "                                'triplet array. If not then debugg it :)')\n",
    "                        logging.info(\"Fold = %s, Epoch = %s, Loss = %s\",\n",
    "                                     str(self.nFold), str(self.epoch), \"{:.6f}\".format(batch_loss))\n",
    "                \n",
    "                print(\"Fold: \" + str(self.nFold) +\n",
    "                      \", Epoch= \" + str(self.epoch) +\n",
    "                      \", Loss= \" + \"{:.6f}\".format(batch_loss))\n",
    "                #                     self.myNet['learning_rate'] = float(self.myNet['learning_rate']/2)\n",
    "                \n",
    "                save_path = saver.save(sess,\n",
    "                                       os.path.join(path_dict['checkpoint_path'], \"distinct_stratified_model.ckpt\"))\n",
    "                \n",
    "                # Now that we have updated our parameters (weights and biases), we would\n",
    "                # fetch the embeddings using the updated parameter and train-test model\n",
    "                # to get an accuracy. Accuracy per epoch is now a good way to go\n",
    "                self.setNewWeights(sess)  # replace the last layer's inception weights with leared finetuned weights\n",
    "                \n",
    "                # TRAIN, GET TRAINING PREDICTION AND ACCURACY\n",
    "                trnX_ = trnX.reshape(-1, trnX.shape[2], trnX.shape[3], trnX.shape[4])  # accumulate all batches\n",
    "                trnY_ = trnY.flatten()\n",
    "                train_labels, _ = self.train(trnX_, trnY_, sess)\n",
    "                tr_acc = self.accuracy(y=trnY_, y_hat=train_labels)\n",
    "                print(\"Fold: %s, Train acc = %s \" % (str(self.nFold), str(tr_acc)))\n",
    "                \n",
    "                # GET CROSS VALIDATION PREDICTION AND ACCURACY\n",
    "                cv_labels, _ = self.cvalid(cvX, sess)\n",
    "                cv_acc = self.accuracy(y=cvY, y_hat=cv_labels)\n",
    "                print(\"Fold: %s, CV acc = %s \" % (str(self.nFold), str(cv_acc)))\n",
    "        \n",
    "        return tr_acc, cv_acc\n",
    "    \n",
    "    def run(self, weightsIN):\n",
    "        self.weights = weightsIN\n",
    "        # GET THE BATCH DATA FROM THE DISK\n",
    "        dataX, dataY, labelDict = DataFormatter.getPickleFile(\n",
    "                folderPath=path_dict['batchFolderPath'], picklefileName=which_file, getStats=True\n",
    "        )\n",
    "        trnBatch_idx = [list(np.setdiff1d(np.arange(len(dataX)), np.array(i))) for i in np.arange(len(dataX))]\n",
    "        cvBatch_idx = [i for i in np.arange(len(dataX))]\n",
    "        logging.info('dataX.shape = %s, dataY.shape = %s', str(dataX.shape), str(dataY.shape))\n",
    "        \n",
    "        # LOOP FOR N-FOLD CROSS VALIDATION\n",
    "        avg_tr_acc = 0\n",
    "        avg_cv_acc = 0\n",
    "        # NOTE WE HAVE TO RESET THE WEIGHTS to the Inception weights every FOLD\n",
    "        for nFold, (trn_batch_idx, cv_batch_idx) in enumerate(zip(trnBatch_idx, cvBatch_idx)):\n",
    "            self.nFold = nFold + 1\n",
    "            logging.info('RUNNING : %s FOLD ...........................', str(self.nFold))\n",
    "            trnX = dataX[trn_batch_idx, :]\n",
    "            trnY = dataY[trn_batch_idx, :]\n",
    "            cvX = dataX[cv_batch_idx, :]\n",
    "            cvY = dataY[cv_batch_idx, :]\n",
    "            logging.info('trnX.shape = %s, trnY.shape = %s, cvX.shape = %s, cvY.shape = %s',\n",
    "                         str(trnX.shape), str(trnY.shape), str(cvX.shape), str(cvY.shape))\n",
    "            \n",
    "            \n",
    "            # RESET AND CREATE THE GRAPH\n",
    "            reset_graph()\n",
    "            self.trn_embed_graph = trainEmbeddings(self.weights, init_wght_type='random')\n",
    "            self.preprocessGraphDict = Preprocessing().preprocessImageGraph(\n",
    "                imageShape=self.myNet[\"image_shape\"])\n",
    "            # EXECUTE THE SESSION FOR THE CURRENT FOLD\n",
    "            tr_acc, cv_acc = self.sess_exec(trnX, trnY, cvX, cvY)\n",
    "            self.resetWeights(weightsIN)\n",
    "            \n",
    "            avg_tr_acc = avg_tr_acc + tr_acc\n",
    "            avg_cv_acc = avg_cv_acc + cv_acc\n",
    "            # add ops to save and restore model\n",
    "            print('')\n",
    "            \n",
    "            print(\"Total %s Folds, Avg Train acc = %s, Avg CV acc = %s \" % (str(self.nFold),\n",
    "                                                                            str(round(avg_tr_acc / self.nFold, 3)),\n",
    "                                                                            str(round(avg_cv_acc / self.nFold, 3)))\n",
    "                  )\n",
    "\n",
    "\n",
    "objExec = Execute(myNet=myNet, embeddingType='finetune')\n",
    "objExec.run(weightsIN=moduleWeightDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGH\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 3, 5]\n",
      "5\n",
      "[[[[ 10.41702175  10.72032452  10.00011444  10.30233288  10.14675617]\n",
      "   [ 10.09233856  10.18626022  10.34556103  10.39676762  10.53881645]\n",
      "   [ 10.41919422  10.68521976  10.20445251  10.87811756  10.02738762]]]]\n",
      "[ 10.30951786  10.5306015   10.18337631  10.52573872  10.23765373]\n",
      "[5]\n",
      "[ 0.02358428  0.05949085  0.020111    0.06357152  0.0477244 ]\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "tfdata = tf.cast(np.random.rand(1,1,3,5) + 10, dtype=tf.float32)\n",
    "print (tfdata.get_shape().as_list())\n",
    "print (tfdata.get_shape()[-1])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batchMean, batchVar = tf.nn.moments(tfdata, axes=[0,1,2], name=\"moments\")\n",
    "    print (tfdata.eval())\n",
    "    print (batchMean.eval())\n",
    "    print (batchMean.get_shape().as_list())\n",
    "    print (batchVar.eval())\n",
    "    print (batchVar.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3,4])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# reset_graph()\n",
    "# def my_func(x):\n",
    "#     return [x]\n",
    "\n",
    "# inp = tf.placeholder(tf.int64)\n",
    "# inp2 = tf.placeholder(tf.float)\n",
    "# y = tf.py_func(my_func, [inp], tf.int64)\n",
    "# y_1 = tf.add(y[:,0], 1)\n",
    "# # print (len(y))#.get_shape())\n",
    "\n",
    "# # a = np.array([[1,2,3],[4,5,6],[6,7,8]])\n",
    "# a = []\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     try:\n",
    "#         yy = sess.run([y_1],feed_dict={inp:a})\n",
    "#         print (yy)\n",
    "#     except InvalidArgumentError:\n",
    "#         print ('dasdsdsdsdsdsdsds')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Import MNIST data\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# reset_graph()\n",
    "# mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "# # Parameters\n",
    "# learning_rate = 0.01\n",
    "# training_epochs = 25\n",
    "# batch_size = 100\n",
    "# display_step = 1\n",
    "\n",
    "# # tf Graph Input\n",
    "# x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "# y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# # Set model weights\n",
    "# W = tf.Variable(tf.zeros([784, 10]))\n",
    "# b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# # Construct model\n",
    "# pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "# # Minimize error using cross entropy\n",
    "# loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "\n",
    "\n",
    "# global_step = tf.Variable(0, trainable=False)\n",
    "# starter_learning_rate = 0.1\n",
    "# # learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "# #                                            100, 0.96, staircase=True)\n",
    "# learning_rate = tf.train.exponential_decay(starter_learning_rate,\n",
    "#                                                    global_step * 500,  # Used for decay computation\n",
    "#                                                    10000,  # Decay steps\n",
    "#                                                    0.96,  # Decay rate\n",
    "#                                                    staircase=True) \n",
    "# optimizer = (\n",
    "#     tf.train.GradientDescentOptimizer(learning_rate)\n",
    "#     .minimize(loss, global_step=global_step)\n",
    "# )\n",
    "\n",
    "\n",
    "# # Gradient Descent\n",
    "# # optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# # Initialize the variables (i.e. assign their default value)\n",
    "# init = tf.global_variables_initializer()\n",
    "\n",
    "# # Start training\n",
    "# with tf.Session() as sess:\n",
    "\n",
    "#     # Run the initializer\n",
    "#     sess.run(init)\n",
    "\n",
    "#     # Training cycle\n",
    "#     for epoch in range(training_epochs):\n",
    "#         avg_cost = 0.\n",
    "#         total_batch = int(mnist.train.num_examples/batch_size)\n",
    "#         # Loop over all batches\n",
    "#         for num, i in enumerate(range(total_batch)):\n",
    "            \n",
    "#             batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "# #             print (batch_ys)\n",
    "#             # Run optimization op (backprop) and cost op (to get loss value)\n",
    "#             _, c, l = sess.run([optimizer, loss, learning_rate], feed_dict={x: batch_xs,\n",
    "#                                                           y: batch_ys})\n",
    "#             print (epoch, num, l)\n",
    "#             # Compute average loss\n",
    "#             avg_cost += c / total_batch\n",
    "#         print ('################')\n",
    "#         # Display logs per epoch step\n",
    "#         if (epoch+1) % display_step == 0:\n",
    "#             print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "#     print(\"Optimization Finished!\")\n",
    "\n",
    "#     # Test model\n",
    "#     correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "#     # Calculate accuracy\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#     print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
