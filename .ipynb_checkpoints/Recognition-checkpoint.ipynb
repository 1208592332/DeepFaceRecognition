{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from data_transformer.data_formatter import DataFormatter\n",
    "from data_transformer.preprocess import Preprocessing\n",
    "\n",
    "from data_transformer.data_prep import DataIO, genDistinctStratifiedBatches, genRandomStratifiedBatches\n",
    "from nn.load_params import layer_name, convShape, getWeights\n",
    "from nn.utils import getTriplets, tripletLoss\n",
    "from train_test.model import *\n",
    "from train_test.classify import SVM\n",
    "from config import path_dict\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logfile.log\", filemode=\"w\",\n",
    "                    format=\"%(asctime)-15s %(levelname)-8s %(message)s\")\n",
    "\n",
    "training = False\n",
    "verification = False\n",
    "create_batches = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE TIME RUN: \n",
    "------------\n",
    "#### INPUT :  Folder path with images of several people, ensure the image folders are named with the person name\n",
    "#### OUTPUT: Dumps a pickle file with three keys, dataX, dataY, labelDict. \n",
    "            * dataX: images converted into nd array\n",
    "            * dataY: for each record of nd array, Labels are numerical (1,2,3,4,5)\n",
    "            * labelDict: Contains the label corresponding to person name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training:\n",
    "    objDP = DataFormatter(path_dict['parent_path'], 'training')\n",
    "    objDP.createResizedData()\n",
    "    dataX, dataY, labelDict = objDP.imageToArray()\n",
    "    DataFormatter.dumpPickleFile(dataX, dataY, labelDict,\n",
    "                               folderPath=os.path.join(path_dict['data_model_path']),\n",
    "                               picklefileName='training_imgarr.pickle')\n",
    "if verification:\n",
    "    objDP = DataFormatter(path_dict['parent_path'], 'verification')\n",
    "    objDP.createResizedData()\n",
    "    dataX, dataY, labelDict = objDP.imageToArray()\n",
    "    DataFormatter.dumpPickleFile(dataX, dataY, labelDict,\n",
    "                               folderPath=os.path.join(path_dict['data_model_path']),\n",
    "                               picklefileName='verification_imgarr.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE RANDOM BATCHES:\n",
    "----------------\n",
    "#### INPUT: Image nd array as input  [num_images, imgX, imgY, num_channels]\n",
    "#### OUTPUT: Outputs a pickle file with shape [num_batches, num_image_per_batch, imgX, imgY, num_channels]\n",
    "\n",
    "       *  We would wanna do stocastic descent for minibatches and update the parameters perbatch. This module attempts to create stratified batches (each batch would have equal distribution of labels). \n",
    "       \n",
    "       * when genDistinctStratifiedBatches. The images in the batched would be distinct (would not repeat)\n",
    "       * when genRandomStratifiedBatches. No seed is set for shuffling. So Images in different batches may repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if create_batches:\n",
    "    trainX, trainY, trainLabelDict = DataIO.getPickleFile(path_dict['data_model_path'],\n",
    "                                                                 'training_imgarr.pickle')\n",
    "    verX, verY, verLabelDict = DataIO.getPickleFile(path_dict['data_model_path'],\n",
    "                                                           'verification_imgarr.pickle')\n",
    "    print(trainX.shape, trainY.shape)\n",
    "    print(verX.shape, verY.shape)\n",
    "    genDistinctStratifiedBatches(trainX, trainY,\n",
    "                          fileName='distinct_stratified_batches.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## RESET TENSORFLOW GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET INCEPTION WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "moduleWeightDict = getWeights(path_dict['inception_nn4small_weights_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO's:\n",
    "\n",
    "1. Remove the random weight initialiazer for the last layer, and initialize it \n",
    "   with the inception net weights.  **DONE**\n",
    "\n",
    "2. implement a module to save weights as checkpoints to the disk.  **DONE**\n",
    "\n",
    "3. create a function to toggle between Random weight initializer, Inception net weight initializer \n",
    "   and using the saved checkpoint for the last Inception layer. **DONE**\n",
    "   \n",
    "4 : REMEBER TO STORE THE exponential weighted average of mean and variable in the batch normalization \n",
    "      fine tune function. SET THESE AS A VARIABLE (LOOK AT CIFAR CODE FOR HELP) **DONE**\n",
    " \n",
    "5. Add more images.\n",
    "\n",
    "6. Create a complete workflow train the network and perform cross validation: **DONE**\n",
    "\n",
    "7. Store 1 image encodings for the 3-4 labels you have.\n",
    "\n",
    "8. For a new image, pass the image throught network, get the encoding and see which is the most closest face using the encoding from the step 6.\n",
    "\n",
    "9. Try :\n",
    "    1. SVM classfication on embedding feature space: Get cross validation accuracy: **DONE**\n",
    "    2. Softmax classification on embedding feature space: Get cross validation accuracy. \n",
    "    \n",
    "10. The triplet selection now has, random selection of Hard negative. Having random selection makes it difficult to adjust parameters. So make is generated by a sedd, but the sees itself should be generated randomly via a different sees. Since having the same seeed decide a triplet would be problematic becasue the same hard negative would always be selected. **DONE**\n",
    "\n",
    "11. Add learning rate decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from __future__ import division, print_function, absolute_import\n",
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.externals import joblib\n",
    "\n",
    "# class SVM():\n",
    "#     '''\n",
    "#     # The embeddings in a nutshell are features. The face image goes through a complex network and results in\n",
    "#     # embeddings that captures complex features of a face. SVM's are good at classifying small datasets.\n",
    "#     # SVM are also robust to over fitting. The idea here is that we would wanna learn a SVM classifier using the\n",
    "#     # embeddings as the feature space and see for the given embedding, how many times we are able to predict the\n",
    "#     # correct class\n",
    "#     '''\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "    \n",
    "#     def train(self, embeddings, labels, model_name=None):\n",
    "#         '''\n",
    "#         :param embeddings:   Embeddings of the image\n",
    "#         :param labels:       labels\n",
    "#         :return:\n",
    "#         '''\n",
    "#         model = SVC(kernel='linear', probability=True)\n",
    "#         model.fit(embeddings, labels)\n",
    "#         joblib.dump(model, os.path.join(path_dict['classification_model_path'], str(model_name)+\"_svm.sav\"))\n",
    "        \n",
    "#     def classify(self, embeddings, model_name=None):\n",
    "#         '''\n",
    "#         :param embeddings: Image embeddings to classify\n",
    "#         :param model_name:\n",
    "#         :return:\n",
    "#         '''\n",
    "#         model = joblib.load(os.path.join(path_dict['classification_model_path'], str(model_name)+\"_svm.sav\"))\n",
    "#         predLabels = model.predict_proba(embeddings)\n",
    "#         top_label_idx = np.argmax(predLabels, axis=1)\n",
    "#         labelProb = predLabels[np.arange(len(top_label_idx)), top_label_idx]\n",
    "#         return top_label_idx, labelProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input data (X) is:  (10, 30, 96, 96, 3)\n",
      "The shape of input data (Y) is:  (10, 30)\n",
      "Unique labels in dataY is:  [ 0.  1.  2.]\n",
      "Label dict:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asasasasasas  0.0001\n",
      "Fold: 1, Epoch= 1, Loss= 28.225758\n",
      "asasasasasas  0.0001\n",
      "Fold: 1, Epoch= 1, Loss= 25.516062\n",
      "asasasasasas  0.0001\n",
      "Fold: 1, Epoch= 1, Loss= 27.511787\n",
      "asasasasasas  0.0001\n",
      "Fold: 1, Epoch= 1, Loss= 27.326771\n",
      "asasasasasas  0.0001\n",
      "Fold: 1, Epoch= 1, Loss= 24.080223\n",
      "asasasasasas  0.0001\n",
      "Fold: 1, Epoch= 1, Loss= 25.608582\n",
      "asasasasasas  0.0001\n",
      "Fold: 1, Epoch= 1, Loss= 24.806387\n",
      "asasasasasas  0.0001\n",
      "Fold: 1, Epoch= 1, Loss= 25.493343\n",
      "asasasasasas  0.0001\n",
      "Fold: 1, Epoch= 1, Loss= 26.326994\n",
      "0.774074074074\n",
      "0.633333333333\n",
      "asasasasasas  9.5e-05\n",
      "Fold: 1, Epoch= 2, Loss= 21.787016\n",
      "asasasasasas  9.5e-05\n",
      "Fold: 1, Epoch= 2, Loss= 24.927269\n",
      "asasasasasas  9.5e-05\n",
      "Fold: 1, Epoch= 2, Loss= 24.518860\n",
      "asasasasasas  9.5e-05\n",
      "Fold: 1, Epoch= 2, Loss= 19.129396\n",
      "asasasasasas  9.5e-05\n",
      "Fold: 1, Epoch= 2, Loss= 23.473333\n",
      "asasasasasas  9.5e-05\n",
      "Fold: 1, Epoch= 2, Loss= 20.686478\n",
      "asasasasasas  9.5e-05\n",
      "Fold: 1, Epoch= 2, Loss= 23.580938\n",
      "asasasasasas  9.5e-05\n",
      "Fold: 1, Epoch= 2, Loss= 22.610264\n",
      "asasasasasas  9.5e-05\n",
      "Fold: 1, Epoch= 2, Loss= 22.694290\n",
      "0.762962962963\n",
      "0.8\n",
      "asasasasasas  9.025e-05\n",
      "Fold: 1, Epoch= 3, Loss= 22.576210\n",
      "asasasasasas  9.025e-05\n",
      "Fold: 1, Epoch= 3, Loss= 20.183720\n",
      "asasasasasas  9.025e-05\n",
      "Fold: 1, Epoch= 3, Loss= 22.558477\n",
      "asasasasasas  9.025e-05\n",
      "Fold: 1, Epoch= 3, Loss= 21.356031\n",
      "asasasasasas  9.025e-05\n",
      "Fold: 1, Epoch= 3, Loss= 16.398289\n",
      "asasasasasas  9.025e-05\n",
      "Fold: 1, Epoch= 3, Loss= 14.327732\n",
      "asasasasasas  9.025e-05\n",
      "Fold: 1, Epoch= 3, Loss= 18.394260\n",
      "asasasasasas  9.025e-05\n",
      "Fold: 1, Epoch= 3, Loss= 17.140491\n",
      "asasasasasas  9.025e-05\n",
      "Fold: 1, Epoch= 3, Loss= 20.233110\n",
      "0.803703703704\n",
      "0.833333333333\n",
      "asasasasasas  8.57375e-05\n",
      "Fold: 1, Epoch= 4, Loss= 15.804541\n",
      "asasasasasas  8.57375e-05\n",
      "Fold: 1, Epoch= 4, Loss= 19.266975\n",
      "asasasasasas  8.57375e-05\n",
      "Fold: 1, Epoch= 4, Loss= 21.812546\n",
      "asasasasasas  8.57375e-05\n",
      "Fold: 1, Epoch= 4, Loss= 16.215895\n",
      "asasasasasas  8.57375e-05\n",
      "Fold: 1, Epoch= 4, Loss= 15.257071\n",
      "asasasasasas  8.57375e-05\n",
      "Fold: 1, Epoch= 4, Loss= 13.208126\n",
      "asasasasasas  8.57375e-05\n",
      "Fold: 1, Epoch= 4, Loss= 13.653851\n",
      "asasasasasas  8.57375e-05\n",
      "Fold: 1, Epoch= 4, Loss= 17.350645\n",
      "asasasasasas  8.57375e-05\n",
      "Fold: 1, Epoch= 4, Loss= 18.475309\n",
      "0.833333333333\n",
      "0.8\n",
      "asasasasasas  8.14506e-05\n",
      "Fold: 1, Epoch= 5, Loss= 10.880099\n",
      "asasasasasas  8.14506e-05\n",
      "Fold: 1, Epoch= 5, Loss= 12.541770\n",
      "asasasasasas  8.14506e-05\n",
      "Fold: 1, Epoch= 5, Loss= 17.291845\n",
      "asasasasasas  8.14506e-05\n",
      "Fold: 1, Epoch= 5, Loss= 14.030589\n",
      "asasasasasas  8.14506e-05\n",
      "Fold: 1, Epoch= 5, Loss= 8.556982\n",
      "asasasasasas  8.14506e-05\n",
      "Fold: 1, Epoch= 5, Loss= 12.062514\n",
      "asasasasasas  8.14506e-05\n",
      "Fold: 1, Epoch= 5, Loss= 8.929608\n",
      "asasasasasas  8.14506e-05\n",
      "Fold: 1, Epoch= 5, Loss= 11.108912\n",
      "asasasasasas  8.14506e-05\n",
      "Fold: 1, Epoch= 5, Loss= 15.681614\n",
      "0.822222222222\n",
      "0.766666666667\n",
      "asasasasasas  7.73781e-05\n",
      "Fold: 1, Epoch= 6, Loss= 8.632652\n",
      "asasasasasas  7.73781e-05\n",
      "Fold: 1, Epoch= 6, Loss= 10.272902\n",
      "asasasasasas  7.73781e-05\n",
      "Fold: 1, Epoch= 6, Loss= 17.921551\n",
      "asasasasasas  7.73781e-05\n",
      "Fold: 1, Epoch= 6, Loss= 12.635500\n",
      "asasasasasas  7.73781e-05\n",
      "Fold: 1, Epoch= 6, Loss= 8.209139\n",
      "asasasasasas  7.73781e-05\n",
      "Fold: 1, Epoch= 6, Loss= 9.855166\n",
      "asasasasasas  7.73781e-05\n",
      "Fold: 1, Epoch= 6, Loss= 5.429815\n",
      "asasasasasas  7.73781e-05\n",
      "Fold: 1, Epoch= 6, Loss= 11.872334\n",
      "asasasasasas  7.73781e-05\n",
      "Fold: 1, Epoch= 6, Loss= 11.652506\n",
      "0.814814814815\n",
      "0.833333333333\n",
      "asasasasasas  7.35092e-05\n",
      "Fold: 1, Epoch= 7, Loss= 5.410987\n",
      "asasasasasas  7.35092e-05\n",
      "Fold: 1, Epoch= 7, Loss= 15.435859\n",
      "asasasasasas  7.35092e-05\n",
      "Fold: 1, Epoch= 7, Loss= 14.334496\n",
      "asasasasasas  7.35092e-05\n",
      "Fold: 1, Epoch= 7, Loss= 7.021310\n",
      "asasasasasas  7.35092e-05\n",
      "Fold: 1, Epoch= 7, Loss= 5.942720\n",
      "asasasasasas  7.35092e-05\n",
      "Fold: 1, Epoch= 7, Loss= 13.012293\n",
      "asasasasasas  7.35092e-05\n",
      "Fold: 1, Epoch= 7, Loss= 6.578173\n",
      "asasasasasas  7.35092e-05\n",
      "Fold: 1, Epoch= 7, Loss= 6.136898\n",
      "asasasasasas  7.35092e-05\n",
      "Fold: 1, Epoch= 7, Loss= 9.877390\n",
      "0.803703703704\n",
      "0.833333333333\n",
      "asasasasasas  6.98337e-05\n",
      "Fold: 1, Epoch= 8, Loss= 7.110242\n",
      "asasasasasas  6.98337e-05\n",
      "Fold: 1, Epoch= 8, Loss= 9.223209\n",
      "asasasasasas  6.98337e-05\n",
      "Fold: 1, Epoch= 8, Loss= 7.929533\n",
      "asasasasasas  6.98337e-05\n",
      "Fold: 1, Epoch= 8, Loss= 6.708732\n",
      "asasasasasas  6.98337e-05\n",
      "Fold: 1, Epoch= 8, Loss= 3.176081\n",
      "asasasasasas  6.98337e-05\n",
      "Fold: 1, Epoch= 8, Loss= 6.996727\n",
      "asasasasasas  6.98337e-05\n",
      "Fold: 1, Epoch= 8, Loss= 7.414598\n",
      "asasasasasas  6.98337e-05\n",
      "Fold: 1, Epoch= 8, Loss= 4.469562\n",
      "asasasasasas  6.98337e-05\n",
      "Fold: 1, Epoch= 8, Loss= 5.741746\n",
      "0.814814814815\n",
      "0.766666666667\n",
      "asasasasasas  6.6342e-05\n",
      "Fold: 1, Epoch= 9, Loss= 3.163275\n",
      "asasasasasas  6.6342e-05\n",
      "Fold: 1, Epoch= 9, Loss= 5.798343\n",
      "asasasasasas  6.6342e-05\n",
      "Fold: 1, Epoch= 9, Loss= 6.303909\n",
      "asasasasasas  6.6342e-05\n",
      "Fold: 1, Epoch= 9, Loss= 2.932692\n",
      "asasasasasas  6.6342e-05\n",
      "Fold: 1, Epoch= 9, Loss= 2.579215\n",
      "asasasasasas  6.6342e-05\n",
      "Fold: 1, Epoch= 9, Loss= 4.549567\n",
      "asasasasasas  6.6342e-05\n",
      "Fold: 1, Epoch= 9, Loss= 6.237792\n",
      "asasasasasas  6.6342e-05\n",
      "Fold: 1, Epoch= 9, Loss= 4.722943\n",
      "asasasasasas  6.6342e-05\n",
      "Fold: 1, Epoch= 9, Loss= 3.195127\n",
      "0.803703703704\n",
      "0.766666666667\n",
      "asasasasasas  6.30249e-05\n",
      "Fold: 1, Epoch= 10, Loss= 3.756324\n",
      "asasasasasas  6.30249e-05\n",
      "Fold: 1, Epoch= 10, Loss= 4.363923\n",
      "asasasasasas  6.30249e-05\n",
      "Fold: 1, Epoch= 10, Loss= 7.513323\n",
      "asasasasasas  6.30249e-05\n",
      "Fold: 1, Epoch= 10, Loss= 6.027968\n",
      "asasasasasas  6.30249e-05\n",
      "Fold: 1, Epoch= 10, Loss= 5.138964\n",
      "asasasasasas  6.30249e-05\n",
      "Fold: 1, Epoch= 10, Loss= 4.652965\n",
      "asasasasasas  6.30249e-05\n",
      "Fold: 1, Epoch= 10, Loss= 4.430048\n",
      "asasasasasas  6.30249e-05\n",
      "Fold: 1, Epoch= 10, Loss= 3.530306\n",
      "asasasasasas  6.30249e-05\n",
      "Fold: 1, Epoch= 10, Loss= 4.214112\n",
      "0.803703703704\n",
      "0.833333333333\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "import config\n",
    "from config import myNet\n",
    "\n",
    "which_file = 'distinct_stratified_batches.pickle'\n",
    "checkpoint_file_name = 'distinct_stratified_model'\n",
    "\n",
    "\n",
    "'''\n",
    "dataX = [num_batches, image_per_batch, image_x, image_y, image_channels]\n",
    "dataY = [num_batches, labels]\n",
    "\n",
    "'''\n",
    "\n",
    "class Execute():\n",
    "    def __init__(self, params, myNet, embeddingType='finetune'):\n",
    "        self.params = params\n",
    "        self.embeddingType = embeddingType\n",
    "        self.myNet = myNet\n",
    "        self.myNet['learning_rate'] = 0.0001\n",
    "        \n",
    "    def runPreprocessor(self, dataIN, sess):\n",
    "        preprocessedData = np.ndarray(shape=(dataIN.shape), dtype='float32')\n",
    "        for numImage in np.arange(dataIN.shape[0]):\n",
    "            feed_dict = {\n",
    "                self.preprocessGraphDict['imageIN']:dataIN[numImage,:]\n",
    "            }\n",
    "            preprocessedData[numImage,:] = sess.run(self.preprocessGraphDict['imageOUT'],\n",
    "                                                      feed_dict=feed_dict)\n",
    "        return preprocessedData\n",
    "        \n",
    "    def setNewWeights(self, sess):\n",
    "        logging.info('UPDATING WEITHGS WITH FINETUNED WEIGHTS .........')\n",
    "#         trainableVars = tf.get_collection(ops.GraphKeys.TRAINABLE_VARIABLES)\n",
    "        if self.embeddingType=='finetune':\n",
    "            for learned_vars in config.finetune_variables:\n",
    "                scope, name = learned_vars.split(':')[0].split('/')\n",
    "                if len(self.params[scope][name]) != 0:\n",
    "                    var_ = sess.run(learned_vars)\n",
    "                    logging.info('Updating param with scope %s and name %s and shape %s with shape %s',\n",
    "                                 str(scope), str(name), str(self.params[scope][name].shape), str(var_.shape))\n",
    "                    self.params[scope][name] = var_\n",
    "                else:\n",
    "                    raise ValueError('It seems that the scope %s or variable %s didnt exist in the dictionary ' % (str(scope), str(name)))\n",
    "    \n",
    "    def train(self, trnX_, trnY_, sess):\n",
    "        '''\n",
    "            1. Make the use of getEmbedding to get the graph with last layer parameter updated with the \n",
    "            fine tuned weights.\n",
    "            2. Get the new embedding for batch/epoch using the computation graph\n",
    "            3. Use the embeddings as feature for a classifier (svm/softmax)\n",
    "            4. Classify faces using the new embeddings.\n",
    "        '''\n",
    "        trainEmbedGraph = getEmbeddings(self.myNet['image_shape'], self.params)\n",
    "        embeddings = sess.run(trainEmbedGraph['output'], \n",
    "                              feed_dict={trainEmbedGraph['inpTensor']:trnX_})\n",
    "        logging.info('Training Embeddings shape %s', embeddings.shape)\n",
    "        obj_svm = SVM()\n",
    "        obj_svm.train(embeddings, labels=trnY_, \n",
    "                      model_name='nFold_%s_batch_%s'%(str(self.nFold),str(self.epoch)))\n",
    "        train_labels, train_label_prob = obj_svm.classify(embeddings, \n",
    "                                             model_name='nFold_%s_batch_%s'%(str(self.nFold),str(self.epoch)))\n",
    "        return train_labels, train_label_prob\n",
    "    \n",
    "    def cvalid(self, cvX_, sess):\n",
    "        embedGraph = getEmbeddings(self.myNet['image_shape'], self.params)\n",
    "        embeddings = sess.run(embedGraph['output'], \n",
    "                              feed_dict={embedGraph['inpTensor']:cvX_})\n",
    "        logging.info('Cross validation Embeddings shape %s', embeddings.shape)\n",
    "        obj_svm = SVM()\n",
    "        cv_labels, cv_label_prob = obj_svm.classify(embeddings, \n",
    "                                             model_name='nFold_%s_batch_%s'%(str(self.nFold),str(self.epoch)))\n",
    "        return cv_labels, cv_label_prob\n",
    "    \n",
    "    def accuracy(self, y, y_hat):\n",
    "        return np.mean(np.equal(y_hat, y))\n",
    "    \n",
    "#     def test(self, tstGraph, testBatch, sess):\n",
    "#         # METHOD 2: TO get weights is form of Tensors\n",
    "#         a = saver.restore(sess, os.path.join(checkpoint_path, \"model.ckpt\"))\n",
    "#         trainableVars = tf.get_collection(ops.GraphKeys.TRAINABLE_VARIABLES)\n",
    "#         testDict = getFineTunedEmbeddings([96,96,3], moduleWeightDict, trainableVars, sess)\n",
    "#         embeddings = sess.run([tstGraph['output']], feed_dict={'inpTensor':testBatch})\n",
    "#         return embeddings\n",
    "\n",
    "    def run(self):\n",
    "        # GET THE BATCH DATA FROM THE DISK\n",
    "        dataX, dataY, labelDict = DataFormatter.getPickleFile(\n",
    "            folderPath=path_dict['batchFolderPath'], picklefileName=which_file, getStats=True\n",
    "        )\n",
    "        trnBatch_idx = [list(np.setdiff1d(np.arange(len(dataX)), np.array(i))) for i in  np.arange(len(dataX))]\n",
    "        cvBatch_idx = [i for i in  np.arange(len(dataX))]\n",
    "        logging.info('dataX.shape = %s, dataY.shape = %s',str(dataX.shape), str(dataY.shape))\n",
    "\n",
    "        # Reset graph to do a fresh start\n",
    "        reset_graph()\n",
    "        trn_embed_graph = trainEmbeddings(moduleWeightDict,init_wght_type='random')\n",
    "        self.preprocessGraphDict = Preprocessing().preprocessImageGraph(\n",
    "                                                            imageShape=self.myNet[\"image_shape\"])\n",
    "        # add ops to save and restore model\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            checkpoints = [ck for ck in os.listdir(path_dict['checkpoint_path']) if ck!='.DS_Store']\n",
    "            if len(checkpoints) > 0 and self.myNet['use_checkpoint']:\n",
    "                saver.restore(sess, os.path.join(path_dict['checkpoint_path'], \n",
    "                                                 \"distinct_stratified_model.ckpt\"))\n",
    "\n",
    "            # LOOP FOR N-FOLD CROSS VALIDATION\n",
    "            for nFold, (trn_batch_idx, cv_batch_idx) in enumerate(zip(trnBatch_idx, cvBatch_idx)):\n",
    "                self.nFold = nFold + 1\n",
    "                logging.info('RUNNING : %s FOLD ...........................', str(self.nFold))\n",
    "                trnX = dataX[trn_batch_idx,:]\n",
    "                trnY = dataY[trn_batch_idx,:]\n",
    "                cvX = dataX[cv_batch_idx,:]\n",
    "                cvY = dataY[cv_batch_idx,:]\n",
    "                logging.info('trnX.shape = %s, trnY.shape = %s, cvX.shape = %s, cvY.shape = %s', \n",
    "                      str(trnX.shape), str(trnY.shape), str(cvX.shape), str(cvY.shape))\n",
    "\n",
    "                for epoch in np.arange(10):\n",
    "                    self.epoch = epoch + 1\n",
    "                    logging.info('RUNNING : %s EPOCH ........................', str(self.epoch))\n",
    "                    # Below loop will minimize the triplet loss and update the parameters\n",
    "                    for batchNum, batchX in enumerate(trnX[0:len(trnX),:]):\n",
    "                        logging.info('RUNNING BATCH %s for shape = %s', str(batchNum + 1), str(batchX.shape))\n",
    "                        \n",
    "                        # Step1 : Preprocess the Data\n",
    "                        preprocessedData = self.runPreprocessor(dataIN=batchX, sess=sess)\n",
    "                            \n",
    "                        # Since we improve on our previous prediction, there can be cases where the network has learned a good enough\n",
    "                        # decision boundary (for a batch) and is unable to find hard negative for the triplet selection. In such a case\n",
    "                        # the network would return an empty array, which would raise a run time exception during the graph is computed.\n",
    "                        # For such cases we would except an exception, and let the graph proceed. \n",
    "                        try:\n",
    "                            opt, batch_loss, lr = sess.run([trn_embed_graph['optimizer'], \n",
    "                                                        trn_embed_graph['loss'],\n",
    "                                                        trn_embed_graph['learning_rate']], \n",
    "                                                        feed_dict={trn_embed_graph['inpTensor']:preprocessedData})\n",
    "                            print ('asasasasasas ', lr)\n",
    "                        except Exception:\n",
    "                            logging.info('Exception Raised! Check the log file and confirm if the exception is becasue of empty triplet array. If not then debugg it :)')       \n",
    "                            logging.info(\"Fold = %s, Epoch = %s, Loss = %s\", \n",
    "                                         str(self.nFold), str(self.epoch), \"{:.6f}\".format(batch_loss))\n",
    "                            \n",
    "                        print(\"Fold: \" + str(self.nFold) + \n",
    "                              \", Epoch= \" + str(self.epoch) + \n",
    "                              \", Loss= \" + \"{:.6f}\".format(batch_loss))\n",
    "#                     self.myNet['learning_rate'] = float(self.myNet['learning_rate']/2)\n",
    "                    \n",
    "                    save_path = saver.save(sess, os.path.join(path_dict['checkpoint_path'], \"distinct_stratified_model.ckpt\"))\n",
    "                    \n",
    "\n",
    "                    # Now that we have updated our parameters (weights and biases), we would\n",
    "                    # fetch the embeddings using the updated parameter and train-test model\n",
    "                    # to get an accuracy. Accuracy per epoch is now a good way to go\n",
    "                    self.setNewWeights(sess) # replace the last layer's inception weights with leared finetuned weights\n",
    "                    \n",
    "                    # TRAIN, GET TRAINING PREDICTION AND ACCURACY\n",
    "                    trnX_ = trnX.reshape(-1, trnX.shape[2], trnX.shape[3], trnX.shape[4]) # accumulate all batches\n",
    "                    trnY_ = trnY.flatten()\n",
    "                    train_labels, _ = self.train(trnX_, trnY_, sess)\n",
    "                    tr_acc = self.accuracy(y=trnY_, y_hat=train_labels)\n",
    "                    print (tr_acc)\n",
    "                    \n",
    "                    # GET CROSS VALIDATION PREDICTION AND ACCURACY\n",
    "                    cv_labels, _ = self.cvalid(cvX, sess)\n",
    "                    cv_acc = self.accuracy(y=cvY, y_hat=cv_labels)\n",
    "                    print (cv_acc)\n",
    "                    \n",
    "#                     break\n",
    "\n",
    "                break\n",
    "\n",
    "objExec = Execute(params=moduleWeightDict, myNet=myNet, embeddingType='finetune')\n",
    "objExec.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS SUMMARY:\n",
    "-------------\n",
    "\n",
    "For any deep learning problem, it is important to have more and more data. Our analysis, infact shows that this is true. Additionally, other stuffs like Exponential weighted average Batch normalization makes the model more robust.\n",
    "\n",
    "* First we try to finetune the last layer of inception net with 90 images (30 image each label) and without exp weighted batch normalization. The accuracy of the model was very poor, jumping between 10% to 60%.\n",
    "\n",
    "* Then we added more data 180 images (+30 images each label) the model performed little better than the previous model. But still the outcomes were inconsistent.\n",
    "\n",
    "* Adding Exponential batch norm , made the results consistent accross runs. But we still had accuracy droping to 10%-20% per batch.\n",
    "\n",
    "* We added more data 300 images (100 images per label). The results were far batter than the previous run and were also consistent. The results at this point were consistent. Cross validation 1 batch accuracy was between 60 to 70 percent. The problem however was that the accuracy decreased after epoch 6. Early stopping could help.\n",
    "\n",
    "* After adding learning rate decay, as expected the cross validation accuracy gets more consistent accross different batches and produces a accuracy of 83% at epoch 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO NOTE:\n",
    "\n",
    "The triplet selection is differnt for every differnt run even after having seed. This could be because small changes in embedding may initiate different triplet seletion. Embedding can be different becasue we have many random preprocessing steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGH\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 3, 5]\n",
      "5\n",
      "[[[[ 10.41702175  10.72032452  10.00011444  10.30233288  10.14675617]\n",
      "   [ 10.09233856  10.18626022  10.34556103  10.39676762  10.53881645]\n",
      "   [ 10.41919422  10.68521976  10.20445251  10.87811756  10.02738762]]]]\n",
      "[ 10.30951786  10.5306015   10.18337631  10.52573872  10.23765373]\n",
      "[5]\n",
      "[ 0.02358428  0.05949085  0.020111    0.06357152  0.0477244 ]\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "tfdata = tf.cast(np.random.rand(1,1,3,5) + 10, dtype=tf.float32)\n",
    "print (tfdata.get_shape().as_list())\n",
    "print (tfdata.get_shape()[-1])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batchMean, batchVar = tf.nn.moments(tfdata, axes=[0,1,2], name=\"moments\")\n",
    "    print (tfdata.eval())\n",
    "    print (batchMean.eval())\n",
    "    print (batchMean.get_shape().as_list())\n",
    "    print (batchVar.eval())\n",
    "    print (batchVar.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3,4])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reset_graph()\n",
    "# def my_func(x):\n",
    "#     return [x]\n",
    "\n",
    "# inp = tf.placeholder(tf.int64)\n",
    "# inp2 = tf.placeholder(tf.float)\n",
    "# y = tf.py_func(my_func, [inp], tf.int64)\n",
    "# y_1 = tf.add(y[:,0], 1)\n",
    "# # print (len(y))#.get_shape())\n",
    "\n",
    "# # a = np.array([[1,2,3],[4,5,6],[6,7,8]])\n",
    "# a = []\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     try:\n",
    "#         yy = sess.run([y_1],feed_dict={inp:a})\n",
    "#         print (yy)\n",
    "#     except InvalidArgumentError:\n",
    "#         print ('dasdsdsdsdsdsdsds')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Import MNIST data\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# reset_graph()\n",
    "# mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "# # Parameters\n",
    "# learning_rate = 0.01\n",
    "# training_epochs = 25\n",
    "# batch_size = 100\n",
    "# display_step = 1\n",
    "\n",
    "# # tf Graph Input\n",
    "# x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "# y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# # Set model weights\n",
    "# W = tf.Variable(tf.zeros([784, 10]))\n",
    "# b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# # Construct model\n",
    "# pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "# # Minimize error using cross entropy\n",
    "# loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "\n",
    "\n",
    "# global_step = tf.Variable(0, trainable=False)\n",
    "# starter_learning_rate = 0.1\n",
    "# # learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "# #                                            100, 0.96, staircase=True)\n",
    "# learning_rate = tf.train.exponential_decay(starter_learning_rate,\n",
    "#                                                    global_step * 500,  # Used for decay computation\n",
    "#                                                    10000,  # Decay steps\n",
    "#                                                    0.96,  # Decay rate\n",
    "#                                                    staircase=True) \n",
    "# optimizer = (\n",
    "#     tf.train.GradientDescentOptimizer(learning_rate)\n",
    "#     .minimize(loss, global_step=global_step)\n",
    "# )\n",
    "\n",
    "\n",
    "# # Gradient Descent\n",
    "# # optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# # Initialize the variables (i.e. assign their default value)\n",
    "# init = tf.global_variables_initializer()\n",
    "\n",
    "# # Start training\n",
    "# with tf.Session() as sess:\n",
    "\n",
    "#     # Run the initializer\n",
    "#     sess.run(init)\n",
    "\n",
    "#     # Training cycle\n",
    "#     for epoch in range(training_epochs):\n",
    "#         avg_cost = 0.\n",
    "#         total_batch = int(mnist.train.num_examples/batch_size)\n",
    "#         # Loop over all batches\n",
    "#         for num, i in enumerate(range(total_batch)):\n",
    "            \n",
    "#             batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "# #             print (batch_ys)\n",
    "#             # Run optimization op (backprop) and cost op (to get loss value)\n",
    "#             _, c, l = sess.run([optimizer, loss, learning_rate], feed_dict={x: batch_xs,\n",
    "#                                                           y: batch_ys})\n",
    "#             print (epoch, num, l)\n",
    "#             # Compute average loss\n",
    "#             avg_cost += c / total_batch\n",
    "#         print ('################')\n",
    "#         # Display logs per epoch step\n",
    "#         if (epoch+1) % display_step == 0:\n",
    "#             print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "#     print(\"Optimization Finished!\")\n",
    "\n",
    "#     # Test model\n",
    "#     correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "#     # Calculate accuracy\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#     print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
